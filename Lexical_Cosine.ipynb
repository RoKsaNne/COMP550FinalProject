{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "362ff01a-8680-489e-9b12-8a529472a60c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from collections import Counter\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import string\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "def tokenize(text):\n",
    "    # Tokenize the text into words, removing punctuation and converting to lowercase\n",
    "    return Counter(text.translate(str.maketrans('', '', string.punctuation)).lower().split())\n",
    "\n",
    "def lexical_similarity(text1, text2):\n",
    "    # Calculate lexical similarity based on common tokens\n",
    "    tokens1 = tokenize(text1)\n",
    "    tokens2 = tokenize(text2)\n",
    "    common_tokens = tokens1 & tokens2\n",
    "    total_tokens = sum(tokens1.values()) + sum(tokens2.values())\n",
    "    return sum(common_tokens.values()) * 2 / total_tokens if total_tokens > 0 else 0\n",
    "\n",
    "def batch_cosine_similarity(texts1, texts2, batch_size=100):\n",
    "    similarities = []\n",
    "    vectorizer = CountVectorizer()\n",
    "\n",
    "    for i in range(0, len(texts1), batch_size):\n",
    "        # Prepare batch data\n",
    "        end = i + batch_size\n",
    "        batch_texts1 = texts1[i:end]\n",
    "        batch_texts2 = texts2[i:end]\n",
    "\n",
    "        # Vectorize the batch texts\n",
    "        vectorizer.fit(batch_texts1 + batch_texts2)\n",
    "        vectors1 = vectorizer.transform(batch_texts1)\n",
    "        vectors2 = vectorizer.transform(batch_texts2)\n",
    "\n",
    "        # Calculate cosine similarity for each pair in the batch\n",
    "        batch_similarities = [cosine_similarity(vectors1[j], vectors2[j])[0,0] \n",
    "                              for j in range(len(batch_texts1))]\n",
    "        similarities.extend(batch_similarities)\n",
    "\n",
    "    return np.mean(similarities)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a38ba580-6706-4305-af44-42fedea89d3a",
   "metadata": {},
   "source": [
    "### EN-FR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "10485768-c8fc-4217-af59-eb79a54fac51",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "b'Skipping line 1250: expected 4 fields, saw 5\\nSkipping line 1680: expected 4 fields, saw 5\\nSkipping line 1810: expected 4 fields, saw 5\\nSkipping line 2161: expected 4 fields, saw 5\\nSkipping line 4531: expected 4 fields, saw 5\\nSkipping line 13379: expected 4 fields, saw 5\\nSkipping line 15111: expected 4 fields, saw 5\\nSkipping line 15457: expected 4 fields, saw 5\\nSkipping line 17265: expected 4 fields, saw 5\\nSkipping line 17986: expected 4 fields, saw 5\\nSkipping line 18421: expected 4 fields, saw 5\\nSkipping line 29019: expected 4 fields, saw 5\\nSkipping line 36181: expected 4 fields, saw 5\\nSkipping line 41179: expected 4 fields, saw 5\\nSkipping line 43631: expected 4 fields, saw 5\\nSkipping line 45641: expected 4 fields, saw 5\\nSkipping line 46177: expected 4 fields, saw 5\\nSkipping line 47418: expected 4 fields, saw 5\\n'\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.2539846592405373, 0.24628111994507534)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file_path_en = 'x-final/en/train.tsv'\n",
    "file_path_fr = 'x-final/fr/translated_train.tsv'\n",
    "df_en = pd.read_csv(file_path_en, delimiter='\\t', error_bad_lines=False)\n",
    "df_fr = pd.read_csv(file_path_fr, delimiter='\\t', error_bad_lines=False)\n",
    "\n",
    "merged_df = pd.merge(df_en, df_fr, on=\"id\", suffixes=('_en', '_fr'))\n",
    "\n",
    "english_texts1 = merged_df['sentence1_en'].astype(str)\n",
    "french_texts1 = merged_df['sentence1_fr'].astype(str)\n",
    "english_texts2 = merged_df['sentence2_en'].astype(str)\n",
    "french_texts2 = merged_df['sentence2_fr'].astype(str)\n",
    "\n",
    "similarities1 = [lexical_similarity(en, fr) for en, fr in zip(english_texts1, french_texts1)]\n",
    "average_similarity1 = sum(similarities1) / len(similarities1) if similarities1 else 0\n",
    "similarities2 = [lexical_similarity(en, fr) for en, fr in zip(english_texts2, french_texts2)]\n",
    "average_similarity2 = sum(similarities2) / len(similarities2) if similarities2 else 0\n",
    "\n",
    "average_lexical_similarity = (average_similarity1+average_similarity2)/2\n",
    "\n",
    "cos_similarities1 = batch_cosine_similarity(english_texts1, french_texts1)\n",
    "cos_similarities2 = batch_cosine_similarity(english_texts2, french_texts2)\n",
    "\n",
    "average_cosine_similarity = (cos_similarities1 + cos_similarities2) / 2\n",
    "\n",
    "average_lexical_similarity, average_cosine_similarity"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e823f011-75c9-4690-a257-51d739662e31",
   "metadata": {},
   "source": [
    "### EN-DE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ad728c78-4bfb-4865-ab1c-a3eceb15b101",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "b'Skipping line 1250: expected 4 fields, saw 5\\nSkipping line 1680: expected 4 fields, saw 5\\nSkipping line 1810: expected 4 fields, saw 5\\nSkipping line 2161: expected 4 fields, saw 5\\nSkipping line 4531: expected 4 fields, saw 5\\nSkipping line 13379: expected 4 fields, saw 5\\nSkipping line 15111: expected 4 fields, saw 5\\nSkipping line 15457: expected 4 fields, saw 5\\nSkipping line 17265: expected 4 fields, saw 5\\nSkipping line 17986: expected 4 fields, saw 5\\nSkipping line 18421: expected 4 fields, saw 5\\nSkipping line 29019: expected 4 fields, saw 5\\nSkipping line 36181: expected 4 fields, saw 5\\nSkipping line 41179: expected 4 fields, saw 5\\nSkipping line 43631: expected 4 fields, saw 5\\nSkipping line 45641: expected 4 fields, saw 5\\nSkipping line 46177: expected 4 fields, saw 5\\nSkipping line 47418: expected 4 fields, saw 5\\n'\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.304132061518894, 0.3075392320920287)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file_path_en = 'x-final/en/train.tsv'\n",
    "file_path_de = 'x-final/de/translated_train.tsv'\n",
    "df_en = pd.read_csv(file_path_en, delimiter='\\t', error_bad_lines=False)\n",
    "df_de = pd.read_csv(file_path_de, delimiter='\\t', error_bad_lines=False)\n",
    "\n",
    "merged_df = pd.merge(df_en, df_de, on=\"id\", suffixes=('_en', '_de'))\n",
    "\n",
    "english_texts1 = merged_df['sentence1_en'].astype(str)\n",
    "german_texts1 = merged_df['sentence1_de'].astype(str)\n",
    "english_texts2 = merged_df['sentence2_en'].astype(str)\n",
    "german_texts2 = merged_df['sentence2_de'].astype(str)\n",
    "\n",
    "\n",
    "similarities1 = [lexical_similarity(en, de) for en, de in zip(english_texts1, german_texts1)]\n",
    "average_similarity1 = sum(similarities1) / len(similarities1) if similarities1 else 0\n",
    "similarities2 = [lexical_similarity(en, de) for en, de in zip(english_texts2, german_texts2)]\n",
    "average_similarity2 = sum(similarities2) / len(similarities2) if similarities2 else 0\n",
    "\n",
    "average_lexical_similarity = (average_similarity1+average_similarity2)/2\n",
    "\n",
    "cos_similarities1 = batch_cosine_similarity(english_texts1, german_texts1)\n",
    "cos_similarities2 = batch_cosine_similarity(english_texts2, german_texts2)\n",
    "\n",
    "average_cosine_similarity = (cos_similarities1 + cos_similarities2) / 2\n",
    "\n",
    "average_lexical_similarity, average_cosine_similarity"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d25667bc-6d26-4c4c-b0de-e5e92a5f02ba",
   "metadata": {},
   "source": [
    "### EN-ES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "55040a4a-10a1-43aa-b1b6-3e96607ba6e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "b'Skipping line 1250: expected 4 fields, saw 5\\nSkipping line 1680: expected 4 fields, saw 5\\nSkipping line 1810: expected 4 fields, saw 5\\nSkipping line 2161: expected 4 fields, saw 5\\nSkipping line 4531: expected 4 fields, saw 5\\nSkipping line 13379: expected 4 fields, saw 5\\nSkipping line 15111: expected 4 fields, saw 5\\nSkipping line 15457: expected 4 fields, saw 5\\nSkipping line 17265: expected 4 fields, saw 5\\nSkipping line 17986: expected 4 fields, saw 5\\nSkipping line 18421: expected 4 fields, saw 5\\nSkipping line 29019: expected 4 fields, saw 5\\nSkipping line 36181: expected 4 fields, saw 5\\nSkipping line 41179: expected 4 fields, saw 5\\nSkipping line 43631: expected 4 fields, saw 5\\nSkipping line 45641: expected 4 fields, saw 5\\nSkipping line 46177: expected 4 fields, saw 5\\nSkipping line 47418: expected 4 fields, saw 5\\n'\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.25060848073609454, 0.22769727905546902)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file_path_en = 'x-final/en/train.tsv'\n",
    "file_path_es = 'x-final/es/translated_train.tsv'\n",
    "df_en = pd.read_csv(file_path_en, delimiter='\\t', error_bad_lines=False)\n",
    "df_es = pd.read_csv(file_path_es, delimiter='\\t', error_bad_lines=False)\n",
    "\n",
    "merged_df = pd.merge(df_en, df_es, on=\"id\", suffixes=('_en', '_es'))\n",
    "\n",
    "english_texts1 = merged_df['sentence1_en'].astype(str)\n",
    "spanish_texts1 = merged_df['sentence1_es'].astype(str)\n",
    "english_texts2 = merged_df['sentence2_en'].astype(str)\n",
    "spanish_texts2 = merged_df['sentence2_es'].astype(str)\n",
    "\n",
    "similarities1 = [lexical_similarity(en, es) for en, es in zip(english_texts1, spanish_texts1)]\n",
    "average_similarity1 = sum(similarities1) / len(similarities1) if similarities1 else 0\n",
    "similarities2 = [lexical_similarity(en, es) for en, es in zip(english_texts2, spanish_texts2)]\n",
    "average_similarity2 = sum(similarities2) / len(similarities2) if similarities2 else 0\n",
    "\n",
    "average_lexical_similarity = (average_similarity1+average_similarity2)/2\n",
    "\n",
    "cos_similarities1 = batch_cosine_similarity(english_texts1, spanish_texts1)\n",
    "cos_similarities2 = batch_cosine_similarity(english_texts2, spanish_texts2)\n",
    "\n",
    "average_cosine_similarity = (cos_similarities1 + cos_similarities2) / 2\n",
    "\n",
    "average_lexical_similarity, average_cosine_similarity"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23574432-5bc2-4a9c-a5c6-4256a817cb89",
   "metadata": {},
   "source": [
    "### EN-KO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a36b3dcf-6558-48e6-9691-d336971df28a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "b'Skipping line 1250: expected 4 fields, saw 5\\nSkipping line 1680: expected 4 fields, saw 5\\nSkipping line 1810: expected 4 fields, saw 5\\nSkipping line 2161: expected 4 fields, saw 5\\nSkipping line 4531: expected 4 fields, saw 5\\nSkipping line 13379: expected 4 fields, saw 5\\nSkipping line 15111: expected 4 fields, saw 5\\nSkipping line 15457: expected 4 fields, saw 5\\nSkipping line 17265: expected 4 fields, saw 5\\nSkipping line 17986: expected 4 fields, saw 5\\nSkipping line 18421: expected 4 fields, saw 5\\nSkipping line 29019: expected 4 fields, saw 5\\nSkipping line 36181: expected 4 fields, saw 5\\nSkipping line 41179: expected 4 fields, saw 5\\nSkipping line 43631: expected 4 fields, saw 5\\nSkipping line 45641: expected 4 fields, saw 5\\nSkipping line 46177: expected 4 fields, saw 5\\nSkipping line 47418: expected 4 fields, saw 5\\n'\n",
      "b'Skipping line 1250: expected 4 fields, saw 5\\nSkipping line 1680: expected 4 fields, saw 5\\nSkipping line 2165: expected 4 fields, saw 5\\nSkipping line 7642: expected 4 fields, saw 5\\nSkipping line 15126: expected 4 fields, saw 5\\n'\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.14748268396707015, 0.17332460796386406)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file_path_en = 'x-final/en/train.tsv'\n",
    "file_path_ko = 'x-final/ko/translated_train.tsv'\n",
    "df_en = pd.read_csv(file_path_en, delimiter='\\t', error_bad_lines=False)\n",
    "df_ko = pd.read_csv(file_path_ko, delimiter='\\t', error_bad_lines=False)\n",
    "\n",
    "merged_df = pd.merge(df_en, df_ko, on=\"id\", suffixes=('_en', '_ko'))\n",
    "\n",
    "english_texts1 = merged_df['sentence1_en'].astype(str)\n",
    "korea_texts1 = merged_df['sentence1_ko'].astype(str)\n",
    "english_texts2 = merged_df['sentence2_en'].astype(str)\n",
    "korea_texts2 = merged_df['sentence2_ko'].astype(str)\n",
    "\n",
    "similarities1 = [lexical_similarity(en, ko) for en, ko in zip(english_texts1, korea_texts1)]\n",
    "average_similarity1 = sum(similarities1) / len(similarities1) if similarities1 else 0\n",
    "similarities2 = [lexical_similarity(en, ko) for en, ko in zip(english_texts2, korea_texts2)]\n",
    "average_similarity2 = sum(similarities2) / len(similarities2) if similarities2 else 0\n",
    "\n",
    "average_lexical_similarity = (average_similarity1+average_similarity2)/2\n",
    "\n",
    "cos_similarities1 = batch_cosine_similarity(english_texts1, korea_texts1)\n",
    "cos_similarities2 = batch_cosine_similarity(english_texts2, korea_texts2)\n",
    "\n",
    "average_cosine_similarity = (cos_similarities1 + cos_similarities2) / 2\n",
    "\n",
    "average_lexical_similarity, average_cosine_similarity"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9aea069d-2a1a-4cab-9329-0e18ca9f679f",
   "metadata": {},
   "source": [
    "### EN-JA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4dc4a540-11c9-4999-b259-1544263f4681",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "b'Skipping line 1250: expected 4 fields, saw 5\\nSkipping line 1680: expected 4 fields, saw 5\\nSkipping line 1810: expected 4 fields, saw 5\\nSkipping line 2161: expected 4 fields, saw 5\\nSkipping line 4531: expected 4 fields, saw 5\\nSkipping line 13379: expected 4 fields, saw 5\\nSkipping line 15111: expected 4 fields, saw 5\\nSkipping line 15457: expected 4 fields, saw 5\\nSkipping line 17265: expected 4 fields, saw 5\\nSkipping line 17986: expected 4 fields, saw 5\\nSkipping line 18421: expected 4 fields, saw 5\\nSkipping line 29019: expected 4 fields, saw 5\\nSkipping line 36181: expected 4 fields, saw 5\\nSkipping line 41179: expected 4 fields, saw 5\\nSkipping line 43631: expected 4 fields, saw 5\\nSkipping line 45641: expected 4 fields, saw 5\\nSkipping line 46177: expected 4 fields, saw 5\\nSkipping line 47418: expected 4 fields, saw 5\\n'\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.029509598846015464, 0.07059264691219824)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file_path_en = 'x-final/en/train.tsv'\n",
    "file_path_zh = 'x-final/ja/translated_train.tsv'\n",
    "df_en = pd.read_csv(file_path_en, delimiter='\\t', error_bad_lines=False)\n",
    "df_zh = pd.read_csv(file_path_zh, delimiter='\\t', error_bad_lines=False)\n",
    "\n",
    "merged_df = pd.merge(df_en, df_zh, on=\"id\", suffixes=('_en', '_zh'))\n",
    "\n",
    "english_texts1 = merged_df['sentence1_en'].astype(str)\n",
    "chinese_texts1 = merged_df['sentence1_zh'].astype(str)\n",
    "english_texts2 = merged_df['sentence2_en'].astype(str)\n",
    "chinese_texts2 = merged_df['sentence2_zh'].astype(str)\n",
    "\n",
    "similarities1 = [lexical_similarity(en, zh) for en, zh in zip(english_texts1, chinese_texts1)]\n",
    "average_similarity1 = sum(similarities1) / len(similarities1) if similarities1 else 0\n",
    "similarities2 = [lexical_similarity(en, zh) for en, zh in zip(english_texts2, chinese_texts2)]\n",
    "average_similarity2 = sum(similarities2) / len(similarities2) if similarities2 else 0\n",
    "\n",
    "average_lexical_similarity = (average_similarity1+average_similarity2)/2\n",
    "\n",
    "cos_similarities1 = batch_cosine_similarity(english_texts1, chinese_texts1)\n",
    "cos_similarities2 = batch_cosine_similarity(english_texts2, chinese_texts2)\n",
    "\n",
    "average_cosine_similarity = (cos_similarities1 + cos_similarities2) / 2\n",
    "\n",
    "average_lexical_similarity, average_cosine_similarity"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8df2b11-6231-4cde-89e7-a3c76aea8a16",
   "metadata": {},
   "source": [
    "### EN-ZH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "febc6935-3ee9-4d09-a771-b75bcc3d05f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "b'Skipping line 1250: expected 4 fields, saw 5\\nSkipping line 1680: expected 4 fields, saw 5\\nSkipping line 1810: expected 4 fields, saw 5\\nSkipping line 2161: expected 4 fields, saw 5\\nSkipping line 4531: expected 4 fields, saw 5\\nSkipping line 13379: expected 4 fields, saw 5\\nSkipping line 15111: expected 4 fields, saw 5\\nSkipping line 15457: expected 4 fields, saw 5\\nSkipping line 17265: expected 4 fields, saw 5\\nSkipping line 17986: expected 4 fields, saw 5\\nSkipping line 18421: expected 4 fields, saw 5\\nSkipping line 29019: expected 4 fields, saw 5\\nSkipping line 36181: expected 4 fields, saw 5\\nSkipping line 41179: expected 4 fields, saw 5\\nSkipping line 43631: expected 4 fields, saw 5\\nSkipping line 45641: expected 4 fields, saw 5\\nSkipping line 46177: expected 4 fields, saw 5\\nSkipping line 47418: expected 4 fields, saw 5\\n'\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.02570235768541026, 0.0718408346426059)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file_path_en = 'x-final/en/train.tsv'\n",
    "file_path_zh = 'x-final/zh/translated_train.tsv'\n",
    "df_en = pd.read_csv(file_path_en, delimiter='\\t', error_bad_lines=False)\n",
    "df_zh = pd.read_csv(file_path_zh, delimiter='\\t', error_bad_lines=False)\n",
    "\n",
    "merged_df = pd.merge(df_en, df_zh, on=\"id\", suffixes=('_en', '_zh'))\n",
    "\n",
    "english_texts1 = merged_df['sentence1_en'].astype(str)\n",
    "chinese_texts1 = merged_df['sentence1_zh'].astype(str)\n",
    "english_texts2 = merged_df['sentence2_en'].astype(str)\n",
    "chinese_texts2 = merged_df['sentence2_zh'].astype(str)\n",
    "\n",
    "similarities1 = [lexical_similarity(en, zh) for en, zh in zip(english_texts1, chinese_texts1)]\n",
    "average_similarity1 = sum(similarities1) / len(similarities1) if similarities1 else 0\n",
    "similarities2 = [lexical_similarity(en, zh) for en, zh in zip(english_texts2, chinese_texts2)]\n",
    "average_similarity2 = sum(similarities2) / len(similarities2) if similarities2 else 0\n",
    "\n",
    "average_lexical_similarity = (average_similarity1+average_similarity2)/2\n",
    "\n",
    "cos_similarities1 = batch_cosine_similarity(english_texts1, chinese_texts1)\n",
    "cos_similarities2 = batch_cosine_similarity(english_texts2, chinese_texts2)\n",
    "\n",
    "average_cosine_similarity = (cos_similarities1 + cos_similarities2) / 2\n",
    "\n",
    "average_lexical_similarity, average_cosine_similarity"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "254a3dde-2174-4221-ac90-009948b067ba",
   "metadata": {},
   "source": [
    "### FR-ES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c41a8f9b-8aba-4776-8d0e-402f8887327a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.3215430262362947, 0.36690604375245384)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file_path_en = 'x-final/fr/translated_train.tsv'\n",
    "file_path_zh = 'x-final/es/translated_train.tsv'\n",
    "df_en = pd.read_csv(file_path_en, delimiter='\\t', error_bad_lines=False)\n",
    "df_zh = pd.read_csv(file_path_zh, delimiter='\\t', error_bad_lines=False)\n",
    "\n",
    "merged_df = pd.merge(df_en, df_zh, on=\"id\", suffixes=('_en', '_zh'))\n",
    "\n",
    "english_texts1 = merged_df['sentence1_en'].astype(str)\n",
    "chinese_texts1 = merged_df['sentence1_zh'].astype(str)\n",
    "english_texts2 = merged_df['sentence2_en'].astype(str)\n",
    "chinese_texts2 = merged_df['sentence2_zh'].astype(str)\n",
    "\n",
    "similarities1 = [lexical_similarity(en, zh) for en, zh in zip(english_texts1, chinese_texts1)]\n",
    "average_similarity1 = sum(similarities1) / len(similarities1) if similarities1 else 0\n",
    "similarities2 = [lexical_similarity(en, zh) for en, zh in zip(english_texts2, chinese_texts2)]\n",
    "average_similarity2 = sum(similarities2) / len(similarities2) if similarities2 else 0\n",
    "\n",
    "average_lexical_similarity = (average_similarity1+average_similarity2)/2\n",
    "\n",
    "cos_similarities1 = batch_cosine_similarity(english_texts1, chinese_texts1)\n",
    "cos_similarities2 = batch_cosine_similarity(english_texts2, chinese_texts2)\n",
    "\n",
    "average_cosine_similarity = (cos_similarities1 + cos_similarities2) / 2\n",
    "\n",
    "average_lexical_similarity, average_cosine_similarity"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d9e3ec5-9e77-4777-81d7-a20d8810fc43",
   "metadata": {},
   "source": [
    "### FR-DE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "351d41e2-fb74-4a11-8885-4ceb6eb61b8f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.23260903113208703, 0.23027652423945655)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file_path_ko = 'x-final/fr/translated_train.tsv'\n",
    "file_path_zh = 'x-final/de/translated_train.tsv'\n",
    "df_ko = pd.read_csv(file_path_ko, delimiter='\\t', error_bad_lines=False)\n",
    "df_zh = pd.read_csv(file_path_zh, delimiter='\\t', error_bad_lines=False)\n",
    "\n",
    "merged_df = pd.merge(df_ko, df_zh, on=\"id\", suffixes=('_en', '_zh'))\n",
    "\n",
    "english_texts1 = merged_df['sentence1_en'].astype(str)\n",
    "chinese_texts1 = merged_df['sentence1_zh'].astype(str)\n",
    "english_texts2 = merged_df['sentence2_en'].astype(str)\n",
    "chinese_texts2 = merged_df['sentence2_zh'].astype(str)\n",
    "\n",
    "similarities1 = [lexical_similarity(en, zh) for en, zh in zip(english_texts1, chinese_texts1)]\n",
    "average_similarity1 = sum(similarities1) / len(similarities1) if similarities1 else 0\n",
    "similarities2 = [lexical_similarity(en, zh) for en, zh in zip(english_texts2, chinese_texts2)]\n",
    "average_similarity2 = sum(similarities2) / len(similarities2) if similarities2 else 0\n",
    "\n",
    "average_lexical_similarity = (average_similarity1+average_similarity2)/2\n",
    "\n",
    "cos_similarities1 = batch_cosine_similarity(english_texts1, chinese_texts1)\n",
    "cos_similarities2 = batch_cosine_similarity(english_texts2, chinese_texts2)\n",
    "\n",
    "average_cosine_similarity = (cos_similarities1 + cos_similarities2) / 2\n",
    "\n",
    "average_lexical_similarity, average_cosine_similarity"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9fae3c5-c2dd-4d6e-88b4-36ea365e7fb5",
   "metadata": {},
   "source": [
    "### FR-KO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c45f8f28-3db7-40b6-ab97-be5fbe55b8af",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "b'Skipping line 1250: expected 4 fields, saw 5\\nSkipping line 1680: expected 4 fields, saw 5\\nSkipping line 2165: expected 4 fields, saw 5\\nSkipping line 7642: expected 4 fields, saw 5\\nSkipping line 15126: expected 4 fields, saw 5\\n'\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.13232842953299934, 0.15639689026785789)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file_path_ko = 'x-final/fr/translated_train.tsv'\n",
    "file_path_zh = 'x-final/ko/translated_train.tsv'\n",
    "df_ko = pd.read_csv(file_path_ko, delimiter='\\t', error_bad_lines=False)\n",
    "df_zh = pd.read_csv(file_path_zh, delimiter='\\t', error_bad_lines=False)\n",
    "\n",
    "merged_df = pd.merge(df_ko, df_zh, on=\"id\", suffixes=('_en', '_zh'))\n",
    "\n",
    "english_texts1 = merged_df['sentence1_en'].astype(str)\n",
    "chinese_texts1 = merged_df['sentence1_zh'].astype(str)\n",
    "english_texts2 = merged_df['sentence2_en'].astype(str)\n",
    "chinese_texts2 = merged_df['sentence2_zh'].astype(str)\n",
    "\n",
    "similarities1 = [lexical_similarity(en, zh) for en, zh in zip(english_texts1, chinese_texts1)]\n",
    "average_similarity1 = sum(similarities1) / len(similarities1) if similarities1 else 0\n",
    "similarities2 = [lexical_similarity(en, zh) for en, zh in zip(english_texts2, chinese_texts2)]\n",
    "average_similarity2 = sum(similarities2) / len(similarities2) if similarities2 else 0\n",
    "\n",
    "average_lexical_similarity = (average_similarity1+average_similarity2)/2\n",
    "\n",
    "cos_similarities1 = batch_cosine_similarity(english_texts1, chinese_texts1)\n",
    "cos_similarities2 = batch_cosine_similarity(english_texts2, chinese_texts2)\n",
    "\n",
    "average_cosine_similarity = (cos_similarities1 + cos_similarities2) / 2\n",
    "\n",
    "average_lexical_similarity, average_cosine_similarity"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0add3459-c9b1-44c4-8357-694c0901ebc1",
   "metadata": {},
   "source": [
    "### FR-JA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0a82f8a6-8da7-4313-81ae-db3763b0db34",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.030243125413892544, 0.06359879130102243)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file_path_ko = 'x-final/fr/translated_train.tsv'\n",
    "file_path_zh = 'x-final/ja/translated_train.tsv'\n",
    "df_ko = pd.read_csv(file_path_ko, delimiter='\\t', error_bad_lines=False)\n",
    "df_zh = pd.read_csv(file_path_zh, delimiter='\\t', error_bad_lines=False)\n",
    "\n",
    "merged_df = pd.merge(df_ko, df_zh, on=\"id\", suffixes=('_en', '_zh'))\n",
    "\n",
    "english_texts1 = merged_df['sentence1_en'].astype(str)\n",
    "chinese_texts1 = merged_df['sentence1_zh'].astype(str)\n",
    "english_texts2 = merged_df['sentence2_en'].astype(str)\n",
    "chinese_texts2 = merged_df['sentence2_zh'].astype(str)\n",
    "\n",
    "similarities1 = [lexical_similarity(en, zh) for en, zh in zip(english_texts1, chinese_texts1)]\n",
    "average_similarity1 = sum(similarities1) / len(similarities1) if similarities1 else 0\n",
    "similarities2 = [lexical_similarity(en, zh) for en, zh in zip(english_texts2, chinese_texts2)]\n",
    "average_similarity2 = sum(similarities2) / len(similarities2) if similarities2 else 0\n",
    "\n",
    "average_lexical_similarity = (average_similarity1+average_similarity2)/2\n",
    "\n",
    "cos_similarities1 = batch_cosine_similarity(english_texts1, chinese_texts1)\n",
    "cos_similarities2 = batch_cosine_similarity(english_texts2, chinese_texts2)\n",
    "\n",
    "average_cosine_similarity = (cos_similarities1 + cos_similarities2) / 2\n",
    "\n",
    "average_lexical_similarity, average_cosine_similarity"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35c2d108-4b96-4824-bdeb-e6a27f1a25a8",
   "metadata": {},
   "source": [
    "### FR-ZH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "25785b7b-72a5-4e0d-947d-d36bd975efdc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.028641939401856765, 0.06670960344385476)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file_path_ko = 'x-final/fr/translated_train.tsv'\n",
    "file_path_zh = 'x-final/zh/translated_train.tsv'\n",
    "df_ko = pd.read_csv(file_path_ko, delimiter='\\t', error_bad_lines=False)\n",
    "df_zh = pd.read_csv(file_path_zh, delimiter='\\t', error_bad_lines=False)\n",
    "\n",
    "merged_df = pd.merge(df_ko, df_zh, on=\"id\", suffixes=('_en', '_zh'))\n",
    "\n",
    "english_texts1 = merged_df['sentence1_en'].astype(str)\n",
    "chinese_texts1 = merged_df['sentence1_zh'].astype(str)\n",
    "english_texts2 = merged_df['sentence2_en'].astype(str)\n",
    "chinese_texts2 = merged_df['sentence2_zh'].astype(str)\n",
    "\n",
    "similarities1 = [lexical_similarity(en, zh) for en, zh in zip(english_texts1, chinese_texts1)]\n",
    "average_similarity1 = sum(similarities1) / len(similarities1) if similarities1 else 0\n",
    "similarities2 = [lexical_similarity(en, zh) for en, zh in zip(english_texts2, chinese_texts2)]\n",
    "average_similarity2 = sum(similarities2) / len(similarities2) if similarities2 else 0\n",
    "\n",
    "average_lexical_similarity = (average_similarity1+average_similarity2)/2\n",
    "\n",
    "cos_similarities1 = batch_cosine_similarity(english_texts1, chinese_texts1)\n",
    "cos_similarities2 = batch_cosine_similarity(english_texts2, chinese_texts2)\n",
    "\n",
    "average_cosine_similarity = (cos_similarities1 + cos_similarities2) / 2\n",
    "\n",
    "average_lexical_similarity, average_cosine_similarity"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efcc53e9-358b-4df5-87e0-dabe59078bca",
   "metadata": {},
   "source": [
    "### ES-DE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a7662bed-34f6-41fe-9cc5-13028084f339",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.23723702958357934, 0.2189863065578936)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file_path_ko = 'x-final/es/translated_train.tsv'\n",
    "file_path_zh = 'x-final/de/translated_train.tsv'\n",
    "df_ko = pd.read_csv(file_path_ko, delimiter='\\t', error_bad_lines=False)\n",
    "df_zh = pd.read_csv(file_path_zh, delimiter='\\t', error_bad_lines=False)\n",
    "\n",
    "merged_df = pd.merge(df_ko, df_zh, on=\"id\", suffixes=('_en', '_zh'))\n",
    "\n",
    "english_texts1 = merged_df['sentence1_en'].astype(str)\n",
    "chinese_texts1 = merged_df['sentence1_zh'].astype(str)\n",
    "english_texts2 = merged_df['sentence2_en'].astype(str)\n",
    "chinese_texts2 = merged_df['sentence2_zh'].astype(str)\n",
    "\n",
    "similarities1 = [lexical_similarity(en, zh) for en, zh in zip(english_texts1, chinese_texts1)]\n",
    "average_similarity1 = sum(similarities1) / len(similarities1) if similarities1 else 0\n",
    "similarities2 = [lexical_similarity(en, zh) for en, zh in zip(english_texts2, chinese_texts2)]\n",
    "average_similarity2 = sum(similarities2) / len(similarities2) if similarities2 else 0\n",
    "\n",
    "average_lexical_similarity = (average_similarity1+average_similarity2)/2\n",
    "\n",
    "cos_similarities1 = batch_cosine_similarity(english_texts1, chinese_texts1)\n",
    "cos_similarities2 = batch_cosine_similarity(english_texts2, chinese_texts2)\n",
    "\n",
    "average_cosine_similarity = (cos_similarities1 + cos_similarities2) / 2\n",
    "\n",
    "average_lexical_similarity, average_cosine_similarity"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c61f7419-ada4-4d3f-bad0-4b1ef05d7c60",
   "metadata": {},
   "source": [
    "### ES-KO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a7bdc70e-ef40-4e46-b667-24afdaf0115b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "b'Skipping line 1250: expected 4 fields, saw 5\\nSkipping line 1680: expected 4 fields, saw 5\\nSkipping line 2165: expected 4 fields, saw 5\\nSkipping line 7642: expected 4 fields, saw 5\\nSkipping line 15126: expected 4 fields, saw 5\\n'\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.13887979672407072, 0.153573187334758)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file_path_ko = 'x-final/es/translated_train.tsv'\n",
    "file_path_zh = 'x-final/ko/translated_train.tsv'\n",
    "df_ko = pd.read_csv(file_path_ko, delimiter='\\t', error_bad_lines=False)\n",
    "df_zh = pd.read_csv(file_path_zh, delimiter='\\t', error_bad_lines=False)\n",
    "\n",
    "merged_df = pd.merge(df_ko, df_zh, on=\"id\", suffixes=('_en', '_zh'))\n",
    "\n",
    "english_texts1 = merged_df['sentence1_en'].astype(str)\n",
    "chinese_texts1 = merged_df['sentence1_zh'].astype(str)\n",
    "english_texts2 = merged_df['sentence2_en'].astype(str)\n",
    "chinese_texts2 = merged_df['sentence2_zh'].astype(str)\n",
    "\n",
    "similarities1 = [lexical_similarity(en, zh) for en, zh in zip(english_texts1, chinese_texts1)]\n",
    "average_similarity1 = sum(similarities1) / len(similarities1) if similarities1 else 0\n",
    "similarities2 = [lexical_similarity(en, zh) for en, zh in zip(english_texts2, chinese_texts2)]\n",
    "average_similarity2 = sum(similarities2) / len(similarities2) if similarities2 else 0\n",
    "\n",
    "average_lexical_similarity = (average_similarity1+average_similarity2)/2\n",
    "\n",
    "cos_similarities1 = batch_cosine_similarity(english_texts1, chinese_texts1)\n",
    "cos_similarities2 = batch_cosine_similarity(english_texts2, chinese_texts2)\n",
    "\n",
    "average_cosine_similarity = (cos_similarities1 + cos_similarities2) / 2\n",
    "\n",
    "average_lexical_similarity, average_cosine_similarity"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4ffe8b1-d77f-4061-a322-9a022e8637d9",
   "metadata": {},
   "source": [
    "### ES-JA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "13fd2977-7538-4a35-88f0-31610a1a6ae7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.031267890300259615, 0.06329803931661071)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file_path_ko = 'x-final/es/translated_train.tsv'\n",
    "file_path_zh = 'x-final/ja/translated_train.tsv'\n",
    "df_ko = pd.read_csv(file_path_ko, delimiter='\\t', error_bad_lines=False)\n",
    "df_zh = pd.read_csv(file_path_zh, delimiter='\\t', error_bad_lines=False)\n",
    "\n",
    "merged_df = pd.merge(df_ko, df_zh, on=\"id\", suffixes=('_en', '_zh'))\n",
    "\n",
    "english_texts1 = merged_df['sentence1_en'].astype(str)\n",
    "chinese_texts1 = merged_df['sentence1_zh'].astype(str)\n",
    "english_texts2 = merged_df['sentence2_en'].astype(str)\n",
    "chinese_texts2 = merged_df['sentence2_zh'].astype(str)\n",
    "\n",
    "similarities1 = [lexical_similarity(en, zh) for en, zh in zip(english_texts1, chinese_texts1)]\n",
    "average_similarity1 = sum(similarities1) / len(similarities1) if similarities1 else 0\n",
    "similarities2 = [lexical_similarity(en, zh) for en, zh in zip(english_texts2, chinese_texts2)]\n",
    "average_similarity2 = sum(similarities2) / len(similarities2) if similarities2 else 0\n",
    "\n",
    "average_lexical_similarity = (average_similarity1+average_similarity2)/2\n",
    "\n",
    "cos_similarities1 = batch_cosine_similarity(english_texts1, chinese_texts1)\n",
    "cos_similarities2 = batch_cosine_similarity(english_texts2, chinese_texts2)\n",
    "\n",
    "average_cosine_similarity = (cos_similarities1 + cos_similarities2) / 2\n",
    "\n",
    "average_lexical_similarity, average_cosine_similarity"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f79f555-28c9-4687-afee-2ee0bf02858b",
   "metadata": {},
   "source": [
    "### ES-ZH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8208ad09-af22-4a6d-9f5a-c79af8e33a49",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.028959108854353287, 0.06662804393296569)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file_path_ko = 'x-final/es/translated_train.tsv'\n",
    "file_path_zh = 'x-final/zh/translated_train.tsv'\n",
    "df_ko = pd.read_csv(file_path_ko, delimiter='\\t', error_bad_lines=False)\n",
    "df_zh = pd.read_csv(file_path_zh, delimiter='\\t', error_bad_lines=False)\n",
    "\n",
    "merged_df = pd.merge(df_ko, df_zh, on=\"id\", suffixes=('_en', '_zh'))\n",
    "\n",
    "english_texts1 = merged_df['sentence1_en'].astype(str)\n",
    "chinese_texts1 = merged_df['sentence1_zh'].astype(str)\n",
    "english_texts2 = merged_df['sentence2_en'].astype(str)\n",
    "chinese_texts2 = merged_df['sentence2_zh'].astype(str)\n",
    "\n",
    "similarities1 = [lexical_similarity(en, zh) for en, zh in zip(english_texts1, chinese_texts1)]\n",
    "average_similarity1 = sum(similarities1) / len(similarities1) if similarities1 else 0\n",
    "similarities2 = [lexical_similarity(en, zh) for en, zh in zip(english_texts2, chinese_texts2)]\n",
    "average_similarity2 = sum(similarities2) / len(similarities2) if similarities2 else 0\n",
    "\n",
    "average_lexical_similarity = (average_similarity1+average_similarity2)/2\n",
    "\n",
    "cos_similarities1 = batch_cosine_similarity(english_texts1, chinese_texts1)\n",
    "cos_similarities2 = batch_cosine_similarity(english_texts2, chinese_texts2)\n",
    "\n",
    "average_cosine_similarity = (cos_similarities1 + cos_similarities2) / 2\n",
    "\n",
    "average_lexical_similarity, average_cosine_similarity"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13bc50f7-d374-46fa-ad2e-55d891970dfe",
   "metadata": {},
   "source": [
    "### DE-KO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "332341a3-b4af-4dad-8346-97864507df0b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "b'Skipping line 1250: expected 4 fields, saw 5\\nSkipping line 1680: expected 4 fields, saw 5\\nSkipping line 2165: expected 4 fields, saw 5\\nSkipping line 7642: expected 4 fields, saw 5\\nSkipping line 15126: expected 4 fields, saw 5\\n'\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.14817754017697132, 0.172754893241511)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file_path_ko = 'x-final/de/translated_train.tsv'\n",
    "file_path_zh = 'x-final/ko/translated_train.tsv'\n",
    "df_ko = pd.read_csv(file_path_ko, delimiter='\\t', error_bad_lines=False)\n",
    "df_zh = pd.read_csv(file_path_zh, delimiter='\\t', error_bad_lines=False)\n",
    "\n",
    "merged_df = pd.merge(df_ko, df_zh, on=\"id\", suffixes=('_en', '_zh'))\n",
    "\n",
    "english_texts1 = merged_df['sentence1_en'].astype(str)\n",
    "chinese_texts1 = merged_df['sentence1_zh'].astype(str)\n",
    "english_texts2 = merged_df['sentence2_en'].astype(str)\n",
    "chinese_texts2 = merged_df['sentence2_zh'].astype(str)\n",
    "\n",
    "similarities1 = [lexical_similarity(en, zh) for en, zh in zip(english_texts1, chinese_texts1)]\n",
    "average_similarity1 = sum(similarities1) / len(similarities1) if similarities1 else 0\n",
    "similarities2 = [lexical_similarity(en, zh) for en, zh in zip(english_texts2, chinese_texts2)]\n",
    "average_similarity2 = sum(similarities2) / len(similarities2) if similarities2 else 0\n",
    "\n",
    "average_lexical_similarity = (average_similarity1+average_similarity2)/2\n",
    "\n",
    "cos_similarities1 = batch_cosine_similarity(english_texts1, chinese_texts1)\n",
    "cos_similarities2 = batch_cosine_similarity(english_texts2, chinese_texts2)\n",
    "\n",
    "average_cosine_similarity = (cos_similarities1 + cos_similarities2) / 2\n",
    "\n",
    "average_lexical_similarity, average_cosine_similarity"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef5bceb5-0dd9-4d86-aae1-12cbdffe3e92",
   "metadata": {},
   "source": [
    "### DE-JA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "07f3eb5f-7991-4e60-bd51-3877554e286c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.03487844971891019, 0.06920324881816498)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file_path_ko = 'x-final/de/translated_train.tsv'\n",
    "file_path_zh = 'x-final/ja/translated_train.tsv'\n",
    "df_ko = pd.read_csv(file_path_ko, delimiter='\\t', error_bad_lines=False)\n",
    "df_zh = pd.read_csv(file_path_zh, delimiter='\\t', error_bad_lines=False)\n",
    "\n",
    "merged_df = pd.merge(df_ko, df_zh, on=\"id\", suffixes=('_en', '_zh'))\n",
    "\n",
    "english_texts1 = merged_df['sentence1_en'].astype(str)\n",
    "chinese_texts1 = merged_df['sentence1_zh'].astype(str)\n",
    "english_texts2 = merged_df['sentence2_en'].astype(str)\n",
    "chinese_texts2 = merged_df['sentence2_zh'].astype(str)\n",
    "\n",
    "similarities1 = [lexical_similarity(en, zh) for en, zh in zip(english_texts1, chinese_texts1)]\n",
    "average_similarity1 = sum(similarities1) / len(similarities1) if similarities1 else 0\n",
    "similarities2 = [lexical_similarity(en, zh) for en, zh in zip(english_texts2, chinese_texts2)]\n",
    "average_similarity2 = sum(similarities2) / len(similarities2) if similarities2 else 0\n",
    "\n",
    "average_lexical_similarity = (average_similarity1+average_similarity2)/2\n",
    "\n",
    "cos_similarities1 = batch_cosine_similarity(english_texts1, chinese_texts1)\n",
    "cos_similarities2 = batch_cosine_similarity(english_texts2, chinese_texts2)\n",
    "\n",
    "average_cosine_similarity = (cos_similarities1 + cos_similarities2) / 2\n",
    "\n",
    "average_lexical_similarity, average_cosine_similarity"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51e63e4e-99ae-4d6d-9e7f-b52d246768cc",
   "metadata": {},
   "source": [
    "### DE-ZH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "811ddeac-0b2d-441b-9b27-3dd66c93da00",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.03135730632234393, 0.07151116756042089)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file_path_ko = 'x-final/de/translated_train.tsv'\n",
    "file_path_zh = 'x-final/zh/translated_train.tsv'\n",
    "df_ko = pd.read_csv(file_path_ko, delimiter='\\t', error_bad_lines=False)\n",
    "df_zh = pd.read_csv(file_path_zh, delimiter='\\t', error_bad_lines=False)\n",
    "\n",
    "merged_df = pd.merge(df_ko, df_zh, on=\"id\", suffixes=('_en', '_zh'))\n",
    "\n",
    "english_texts1 = merged_df['sentence1_en'].astype(str)\n",
    "chinese_texts1 = merged_df['sentence1_zh'].astype(str)\n",
    "english_texts2 = merged_df['sentence2_en'].astype(str)\n",
    "chinese_texts2 = merged_df['sentence2_zh'].astype(str)\n",
    "\n",
    "similarities1 = [lexical_similarity(en, zh) for en, zh in zip(english_texts1, chinese_texts1)]\n",
    "average_similarity1 = sum(similarities1) / len(similarities1) if similarities1 else 0\n",
    "similarities2 = [lexical_similarity(en, zh) for en, zh in zip(english_texts2, chinese_texts2)]\n",
    "average_similarity2 = sum(similarities2) / len(similarities2) if similarities2 else 0\n",
    "\n",
    "average_lexical_similarity = (average_similarity1+average_similarity2)/2\n",
    "\n",
    "cos_similarities1 = batch_cosine_similarity(english_texts1, chinese_texts1)\n",
    "cos_similarities2 = batch_cosine_similarity(english_texts2, chinese_texts2)\n",
    "\n",
    "average_cosine_similarity = (cos_similarities1 + cos_similarities2) / 2\n",
    "\n",
    "average_lexical_similarity, average_cosine_similarity"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e99af4cc-0c67-45ea-b525-8ee4684b7030",
   "metadata": {},
   "source": [
    "### KO-JA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "75bb43b9-0583-416d-b223-c9edfefe2856",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "b'Skipping line 1250: expected 4 fields, saw 5\\nSkipping line 1680: expected 4 fields, saw 5\\nSkipping line 2165: expected 4 fields, saw 5\\nSkipping line 7642: expected 4 fields, saw 5\\nSkipping line 15126: expected 4 fields, saw 5\\n'\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.035380390068386745, 0.07249324263925604)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file_path_ko = 'x-final/ko/translated_train.tsv'\n",
    "file_path_zh = 'x-final/ja/translated_train.tsv'\n",
    "df_ko = pd.read_csv(file_path_ko, delimiter='\\t', error_bad_lines=False)\n",
    "df_zh = pd.read_csv(file_path_zh, delimiter='\\t', error_bad_lines=False)\n",
    "\n",
    "merged_df = pd.merge(df_ko, df_zh, on=\"id\", suffixes=('_en', '_zh'))\n",
    "\n",
    "english_texts1 = merged_df['sentence1_en'].astype(str)\n",
    "chinese_texts1 = merged_df['sentence1_zh'].astype(str)\n",
    "english_texts2 = merged_df['sentence2_en'].astype(str)\n",
    "chinese_texts2 = merged_df['sentence2_zh'].astype(str)\n",
    "\n",
    "similarities1 = [lexical_similarity(en, zh) for en, zh in zip(english_texts1, chinese_texts1)]\n",
    "average_similarity1 = sum(similarities1) / len(similarities1) if similarities1 else 0\n",
    "similarities2 = [lexical_similarity(en, zh) for en, zh in zip(english_texts2, chinese_texts2)]\n",
    "average_similarity2 = sum(similarities2) / len(similarities2) if similarities2 else 0\n",
    "\n",
    "average_lexical_similarity = (average_similarity1+average_similarity2)/2\n",
    "\n",
    "cos_similarities1 = batch_cosine_similarity(english_texts1, chinese_texts1)\n",
    "cos_similarities2 = batch_cosine_similarity(english_texts2, chinese_texts2)\n",
    "\n",
    "average_cosine_similarity = (cos_similarities1 + cos_similarities2) / 2\n",
    "\n",
    "average_lexical_similarity, average_cosine_similarity"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73a98b0c-d04a-4435-9a64-ad9408c91bed",
   "metadata": {},
   "source": [
    "### KO-ZH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "9606d0b1-dac0-428a-952c-0a5d193add8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "b'Skipping line 1250: expected 4 fields, saw 5\\nSkipping line 1680: expected 4 fields, saw 5\\nSkipping line 2165: expected 4 fields, saw 5\\nSkipping line 7642: expected 4 fields, saw 5\\nSkipping line 15126: expected 4 fields, saw 5\\n'\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.032682018875849025, 0.06931812695606496)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file_path_ko = 'x-final/ko/translated_train.tsv'\n",
    "file_path_zh = 'x-final/zh/translated_train.tsv'\n",
    "df_ko = pd.read_csv(file_path_ko, delimiter='\\t', error_bad_lines=False)\n",
    "df_zh = pd.read_csv(file_path_zh, delimiter='\\t', error_bad_lines=False)\n",
    "\n",
    "merged_df = pd.merge(df_ko, df_zh, on=\"id\", suffixes=('_en', '_zh'))\n",
    "\n",
    "english_texts1 = merged_df['sentence1_en'].astype(str)\n",
    "chinese_texts1 = merged_df['sentence1_zh'].astype(str)\n",
    "english_texts2 = merged_df['sentence2_en'].astype(str)\n",
    "chinese_texts2 = merged_df['sentence2_zh'].astype(str)\n",
    "\n",
    "similarities1 = [lexical_similarity(en, zh) for en, zh in zip(english_texts1, chinese_texts1)]\n",
    "average_similarity1 = sum(similarities1) / len(similarities1) if similarities1 else 0\n",
    "similarities2 = [lexical_similarity(en, zh) for en, zh in zip(english_texts2, chinese_texts2)]\n",
    "average_similarity2 = sum(similarities2) / len(similarities2) if similarities2 else 0\n",
    "\n",
    "average_lexical_similarity = (average_similarity1+average_similarity2)/2\n",
    "\n",
    "cos_similarities1 = batch_cosine_similarity(english_texts1, chinese_texts1)\n",
    "cos_similarities2 = batch_cosine_similarity(english_texts2, chinese_texts2)\n",
    "\n",
    "average_cosine_similarity = (cos_similarities1 + cos_similarities2) / 2\n",
    "\n",
    "average_lexical_similarity, average_cosine_similarity"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1aea6ea9-4bd1-47ec-b050-ed2cc026e510",
   "metadata": {},
   "source": [
    "### JA-ZH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f9c12ba5-5269-4551-b594-cef6486860ae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.057943033961526766, 0.08756656872188451)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file_path_ko = 'x-final/ja/translated_train.tsv'\n",
    "file_path_zh = 'x-final/zh/translated_train.tsv'\n",
    "df_ko = pd.read_csv(file_path_ko, delimiter='\\t', error_bad_lines=False)\n",
    "df_zh = pd.read_csv(file_path_zh, delimiter='\\t', error_bad_lines=False)\n",
    "\n",
    "merged_df = pd.merge(df_ko, df_zh, on=\"id\", suffixes=('_en', '_zh'))\n",
    "\n",
    "english_texts1 = merged_df['sentence1_en'].astype(str)\n",
    "chinese_texts1 = merged_df['sentence1_zh'].astype(str)\n",
    "english_texts2 = merged_df['sentence2_en'].astype(str)\n",
    "chinese_texts2 = merged_df['sentence2_zh'].astype(str)\n",
    "\n",
    "similarities1 = [lexical_similarity(en, zh) for en, zh in zip(english_texts1, chinese_texts1)]\n",
    "average_similarity1 = sum(similarities1) / len(similarities1) if similarities1 else 0\n",
    "similarities2 = [lexical_similarity(en, zh) for en, zh in zip(english_texts2, chinese_texts2)]\n",
    "average_similarity2 = sum(similarities2) / len(similarities2) if similarities2 else 0\n",
    "\n",
    "average_lexical_similarity = (average_similarity1+average_similarity2)/2\n",
    "\n",
    "cos_similarities1 = batch_cosine_similarity(english_texts1, chinese_texts1)\n",
    "cos_similarities2 = batch_cosine_similarity(english_texts2, chinese_texts2)\n",
    "\n",
    "average_cosine_similarity = (cos_similarities1 + cos_similarities2) / 2\n",
    "\n",
    "average_lexical_similarity, average_cosine_similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd0694bc-0bab-47d3-aac7-ff10616e9c63",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
