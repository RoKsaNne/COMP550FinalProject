{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "362ff01a-8680-489e-9b12-8a529472a60c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     /home/ruohan/nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n",
      "[nltk_data] Downloading package punkt to /home/ruohan/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to /home/ruohan/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import pandas as pd\n",
    "import nltk\n",
    "from nltk import pos_tag\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "\n",
    "def pos_tag_sentence(sentence):\n",
    "    words = word_tokenize(sentence)\n",
    "    words = [word for word in words if word.isalpha()]  # Remove non-alphabetic tokens\n",
    "    return [tag for word, tag in pos_tag(words)]\n",
    "\n",
    "def syntactic_similarity(tags1, tags2):\n",
    "    common_tags = set(tags1) & set(tags2)\n",
    "    total_tags = len(set(tags1 + tags2))\n",
    "    return len(common_tags) / total_tags if total_tags > 0 else 0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a38ba580-6706-4305-af44-42fedea89d3a",
   "metadata": {},
   "source": [
    "### EN-FR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "10485768-c8fc-4217-af59-eb79a54fac51",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "b'Skipping line 1250: expected 4 fields, saw 5\\nSkipping line 1680: expected 4 fields, saw 5\\nSkipping line 1810: expected 4 fields, saw 5\\nSkipping line 2161: expected 4 fields, saw 5\\nSkipping line 4531: expected 4 fields, saw 5\\nSkipping line 13379: expected 4 fields, saw 5\\nSkipping line 15111: expected 4 fields, saw 5\\nSkipping line 15457: expected 4 fields, saw 5\\nSkipping line 17265: expected 4 fields, saw 5\\nSkipping line 17986: expected 4 fields, saw 5\\nSkipping line 18421: expected 4 fields, saw 5\\nSkipping line 29019: expected 4 fields, saw 5\\nSkipping line 36181: expected 4 fields, saw 5\\nSkipping line 41179: expected 4 fields, saw 5\\nSkipping line 43631: expected 4 fields, saw 5\\nSkipping line 45641: expected 4 fields, saw 5\\nSkipping line 46177: expected 4 fields, saw 5\\nSkipping line 47418: expected 4 fields, saw 5\\n'\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.3604336670935255"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file_path_en = 'x-final/en/train.tsv'\n",
    "file_path_fr = 'x-final/fr/translated_train.tsv'\n",
    "df_en = pd.read_csv(file_path_en, delimiter='\\t', error_bad_lines=False)\n",
    "df_fr = pd.read_csv(file_path_fr, delimiter='\\t', error_bad_lines=False)\n",
    "\n",
    "merged_df = pd.merge(df_en, df_fr, on=\"id\", suffixes=('_en', '_fr'))\n",
    "\n",
    "english_texts1 = merged_df['sentence1_en'].astype(str)\n",
    "french_texts1 = merged_df['sentence1_fr'].astype(str)\n",
    "english_texts2 = merged_df['sentence2_en'].astype(str)\n",
    "french_texts2 = merged_df['sentence2_fr'].astype(str)\n",
    "\n",
    "syntactic_similarities1 = [syntactic_similarity(pos_tag_sentence(en), pos_tag_sentence(fr)) for en, fr in zip(english_texts1, french_texts1)]\n",
    "syntactic_similarities2 = [syntactic_similarity(pos_tag_sentence(en), pos_tag_sentence(fr)) for en, fr in zip(english_texts2, french_texts2)]\n",
    "\n",
    "# Calculate average syntactic similarity\n",
    "average_syntactic_similarity1 = sum(syntactic_similarities1) / len(syntactic_similarities1) if syntactic_similarities1 else 0\n",
    "average_syntactic_similarity2 = sum(syntactic_similarities2) / len(syntactic_similarities2) if syntactic_similarities2 else 0\n",
    "\n",
    "average_syntactic_similarity = (average_syntactic_similarity1 + average_syntactic_similarity2) / 2\n",
    "\n",
    "average_syntactic_similarity"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e823f011-75c9-4690-a257-51d739662e31",
   "metadata": {},
   "source": [
    "### EN-DE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ad728c78-4bfb-4865-ab1c-a3eceb15b101",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "b'Skipping line 1250: expected 4 fields, saw 5\\nSkipping line 1680: expected 4 fields, saw 5\\nSkipping line 1810: expected 4 fields, saw 5\\nSkipping line 2161: expected 4 fields, saw 5\\nSkipping line 4531: expected 4 fields, saw 5\\nSkipping line 13379: expected 4 fields, saw 5\\nSkipping line 15111: expected 4 fields, saw 5\\nSkipping line 15457: expected 4 fields, saw 5\\nSkipping line 17265: expected 4 fields, saw 5\\nSkipping line 17986: expected 4 fields, saw 5\\nSkipping line 18421: expected 4 fields, saw 5\\nSkipping line 29019: expected 4 fields, saw 5\\nSkipping line 36181: expected 4 fields, saw 5\\nSkipping line 41179: expected 4 fields, saw 5\\nSkipping line 43631: expected 4 fields, saw 5\\nSkipping line 45641: expected 4 fields, saw 5\\nSkipping line 46177: expected 4 fields, saw 5\\nSkipping line 47418: expected 4 fields, saw 5\\n'\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.3571244274722682"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file_path_en = 'x-final/en/train.tsv'\n",
    "file_path_de = 'x-final/de/translated_train.tsv'\n",
    "df_en = pd.read_csv(file_path_en, delimiter='\\t', error_bad_lines=False)\n",
    "df_de = pd.read_csv(file_path_de, delimiter='\\t', error_bad_lines=False)\n",
    "\n",
    "merged_df = pd.merge(df_en, df_de, on=\"id\", suffixes=('_en', '_de'))\n",
    "\n",
    "english_texts1 = merged_df['sentence1_en'].astype(str)\n",
    "german_texts1 = merged_df['sentence1_de'].astype(str)\n",
    "english_texts2 = merged_df['sentence2_en'].astype(str)\n",
    "german_texts2 = merged_df['sentence2_de'].astype(str)\n",
    "\n",
    "\n",
    "syntactic_similarities1 = [syntactic_similarity(pos_tag_sentence(en), pos_tag_sentence(fr)) for en, fr in zip(english_texts1, german_texts1)]\n",
    "syntactic_similarities2 = [syntactic_similarity(pos_tag_sentence(en), pos_tag_sentence(fr)) for en, fr in zip(english_texts2, german_texts2)]\n",
    "\n",
    "# Calculate average syntactic similarity\n",
    "average_syntactic_similarity1 = sum(syntactic_similarities1) / len(syntactic_similarities1) if syntactic_similarities1 else 0\n",
    "average_syntactic_similarity2 = sum(syntactic_similarities2) / len(syntactic_similarities2) if syntactic_similarities2 else 0\n",
    "\n",
    "average_syntactic_similarity = (average_syntactic_similarity1 + average_syntactic_similarity2) / 2\n",
    "\n",
    "average_syntactic_similarity"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d25667bc-6d26-4c4c-b0de-e5e92a5f02ba",
   "metadata": {},
   "source": [
    "### EN-ES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "55040a4a-10a1-43aa-b1b6-3e96607ba6e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "b'Skipping line 1250: expected 4 fields, saw 5\\nSkipping line 1680: expected 4 fields, saw 5\\nSkipping line 1810: expected 4 fields, saw 5\\nSkipping line 2161: expected 4 fields, saw 5\\nSkipping line 4531: expected 4 fields, saw 5\\nSkipping line 13379: expected 4 fields, saw 5\\nSkipping line 15111: expected 4 fields, saw 5\\nSkipping line 15457: expected 4 fields, saw 5\\nSkipping line 17265: expected 4 fields, saw 5\\nSkipping line 17986: expected 4 fields, saw 5\\nSkipping line 18421: expected 4 fields, saw 5\\nSkipping line 29019: expected 4 fields, saw 5\\nSkipping line 36181: expected 4 fields, saw 5\\nSkipping line 41179: expected 4 fields, saw 5\\nSkipping line 43631: expected 4 fields, saw 5\\nSkipping line 45641: expected 4 fields, saw 5\\nSkipping line 46177: expected 4 fields, saw 5\\nSkipping line 47418: expected 4 fields, saw 5\\n'\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.37393655614023663"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file_path_en = 'x-final/en/train.tsv'\n",
    "file_path_es = 'x-final/es/translated_train.tsv'\n",
    "df_en = pd.read_csv(file_path_en, delimiter='\\t', error_bad_lines=False)\n",
    "df_es = pd.read_csv(file_path_es, delimiter='\\t', error_bad_lines=False)\n",
    "\n",
    "merged_df = pd.merge(df_en, df_es, on=\"id\", suffixes=('_en', '_es'))\n",
    "\n",
    "english_texts1 = merged_df['sentence1_en'].astype(str)\n",
    "spanish_texts1 = merged_df['sentence1_es'].astype(str)\n",
    "english_texts2 = merged_df['sentence2_en'].astype(str)\n",
    "spanish_texts2 = merged_df['sentence2_es'].astype(str)\n",
    "\n",
    "syntactic_similarities1 = [syntactic_similarity(pos_tag_sentence(en), pos_tag_sentence(fr)) for en, fr in zip(english_texts1, spanish_texts1)]\n",
    "syntactic_similarities2 = [syntactic_similarity(pos_tag_sentence(en), pos_tag_sentence(fr)) for en, fr in zip(english_texts2, spanish_texts2)]\n",
    "\n",
    "# Calculate average syntactic similarity\n",
    "average_syntactic_similarity1 = sum(syntactic_similarities1) / len(syntactic_similarities1) if syntactic_similarities1 else 0\n",
    "average_syntactic_similarity2 = sum(syntactic_similarities2) / len(syntactic_similarities2) if syntactic_similarities2 else 0\n",
    "\n",
    "average_syntactic_similarity = (average_syntactic_similarity1 + average_syntactic_similarity2) / 2\n",
    "\n",
    "average_syntactic_similarity"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23574432-5bc2-4a9c-a5c6-4256a817cb89",
   "metadata": {},
   "source": [
    "### EN-KO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a36b3dcf-6558-48e6-9691-d336971df28a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "b'Skipping line 1250: expected 4 fields, saw 5\\nSkipping line 1680: expected 4 fields, saw 5\\nSkipping line 1810: expected 4 fields, saw 5\\nSkipping line 2161: expected 4 fields, saw 5\\nSkipping line 4531: expected 4 fields, saw 5\\nSkipping line 13379: expected 4 fields, saw 5\\nSkipping line 15111: expected 4 fields, saw 5\\nSkipping line 15457: expected 4 fields, saw 5\\nSkipping line 17265: expected 4 fields, saw 5\\nSkipping line 17986: expected 4 fields, saw 5\\nSkipping line 18421: expected 4 fields, saw 5\\nSkipping line 29019: expected 4 fields, saw 5\\nSkipping line 36181: expected 4 fields, saw 5\\nSkipping line 41179: expected 4 fields, saw 5\\nSkipping line 43631: expected 4 fields, saw 5\\nSkipping line 45641: expected 4 fields, saw 5\\nSkipping line 46177: expected 4 fields, saw 5\\nSkipping line 47418: expected 4 fields, saw 5\\n'\n",
      "b'Skipping line 1250: expected 4 fields, saw 5\\nSkipping line 1680: expected 4 fields, saw 5\\nSkipping line 2165: expected 4 fields, saw 5\\nSkipping line 7642: expected 4 fields, saw 5\\nSkipping line 15126: expected 4 fields, saw 5\\n'\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.2628014007472034"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file_path_en = 'x-final/en/train.tsv'\n",
    "file_path_ko = 'x-final/ko/translated_train.tsv'\n",
    "df_en = pd.read_csv(file_path_en, delimiter='\\t', error_bad_lines=False)\n",
    "df_ko = pd.read_csv(file_path_ko, delimiter='\\t', error_bad_lines=False)\n",
    "\n",
    "merged_df = pd.merge(df_en, df_ko, on=\"id\", suffixes=('_en', '_ko'))\n",
    "\n",
    "english_texts1 = merged_df['sentence1_en'].astype(str)\n",
    "korea_texts1 = merged_df['sentence1_ko'].astype(str)\n",
    "english_texts2 = merged_df['sentence2_en'].astype(str)\n",
    "korea_texts2 = merged_df['sentence2_ko'].astype(str)\n",
    "\n",
    "syntactic_similarities1 = [syntactic_similarity(pos_tag_sentence(en), pos_tag_sentence(fr)) for en, fr in zip(english_texts1, korea_texts1)]\n",
    "syntactic_similarities2 = [syntactic_similarity(pos_tag_sentence(en), pos_tag_sentence(fr)) for en, fr in zip(english_texts2, korea_texts2)]\n",
    "\n",
    "# Calculate average syntactic similarity\n",
    "average_syntactic_similarity1 = sum(syntactic_similarities1) / len(syntactic_similarities1) if syntactic_similarities1 else 0\n",
    "average_syntactic_similarity2 = sum(syntactic_similarities2) / len(syntactic_similarities2) if syntactic_similarities2 else 0\n",
    "\n",
    "average_syntactic_similarity = (average_syntactic_similarity1 + average_syntactic_similarity2) / 2\n",
    "\n",
    "average_syntactic_similarity"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9aea069d-2a1a-4cab-9329-0e18ca9f679f",
   "metadata": {},
   "source": [
    "### EN-JA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4dc4a540-11c9-4999-b259-1544263f4681",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "b'Skipping line 1250: expected 4 fields, saw 5\\nSkipping line 1680: expected 4 fields, saw 5\\nSkipping line 1810: expected 4 fields, saw 5\\nSkipping line 2161: expected 4 fields, saw 5\\nSkipping line 4531: expected 4 fields, saw 5\\nSkipping line 13379: expected 4 fields, saw 5\\nSkipping line 15111: expected 4 fields, saw 5\\nSkipping line 15457: expected 4 fields, saw 5\\nSkipping line 17265: expected 4 fields, saw 5\\nSkipping line 17986: expected 4 fields, saw 5\\nSkipping line 18421: expected 4 fields, saw 5\\nSkipping line 29019: expected 4 fields, saw 5\\nSkipping line 36181: expected 4 fields, saw 5\\nSkipping line 41179: expected 4 fields, saw 5\\nSkipping line 43631: expected 4 fields, saw 5\\nSkipping line 45641: expected 4 fields, saw 5\\nSkipping line 46177: expected 4 fields, saw 5\\nSkipping line 47418: expected 4 fields, saw 5\\n'\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.039389559075448645"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file_path_en = 'x-final/en/train.tsv'\n",
    "file_path_zh = 'x-final/ja/translated_train.tsv'\n",
    "df_en = pd.read_csv(file_path_en, delimiter='\\t', error_bad_lines=False)\n",
    "df_zh = pd.read_csv(file_path_zh, delimiter='\\t', error_bad_lines=False)\n",
    "\n",
    "merged_df = pd.merge(df_en, df_zh, on=\"id\", suffixes=('_en', '_zh'))\n",
    "\n",
    "english_texts1 = merged_df['sentence1_en'].astype(str)\n",
    "chinese_texts1 = merged_df['sentence1_zh'].astype(str)\n",
    "english_texts2 = merged_df['sentence2_en'].astype(str)\n",
    "chinese_texts2 = merged_df['sentence2_zh'].astype(str)\n",
    "\n",
    "syntactic_similarities1 = [syntactic_similarity(pos_tag_sentence(en), pos_tag_sentence(fr)) for en, fr in zip(english_texts1, chinese_texts1)]\n",
    "syntactic_similarities2 = [syntactic_similarity(pos_tag_sentence(en), pos_tag_sentence(fr)) for en, fr in zip(english_texts2, chinese_texts2)]\n",
    "\n",
    "# Calculate average syntactic similarity\n",
    "average_syntactic_similarity1 = sum(syntactic_similarities1) / len(syntactic_similarities1) if syntactic_similarities1 else 0\n",
    "average_syntactic_similarity2 = sum(syntactic_similarities2) / len(syntactic_similarities2) if syntactic_similarities2 else 0\n",
    "\n",
    "average_syntactic_similarity = (average_syntactic_similarity1 + average_syntactic_similarity2) / 2\n",
    "\n",
    "average_syntactic_similarity"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8df2b11-6231-4cde-89e7-a3c76aea8a16",
   "metadata": {},
   "source": [
    "### EN-ZH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "febc6935-3ee9-4d09-a771-b75bcc3d05f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "b'Skipping line 1250: expected 4 fields, saw 5\\nSkipping line 1680: expected 4 fields, saw 5\\nSkipping line 1810: expected 4 fields, saw 5\\nSkipping line 2161: expected 4 fields, saw 5\\nSkipping line 4531: expected 4 fields, saw 5\\nSkipping line 13379: expected 4 fields, saw 5\\nSkipping line 15111: expected 4 fields, saw 5\\nSkipping line 15457: expected 4 fields, saw 5\\nSkipping line 17265: expected 4 fields, saw 5\\nSkipping line 17986: expected 4 fields, saw 5\\nSkipping line 18421: expected 4 fields, saw 5\\nSkipping line 29019: expected 4 fields, saw 5\\nSkipping line 36181: expected 4 fields, saw 5\\nSkipping line 41179: expected 4 fields, saw 5\\nSkipping line 43631: expected 4 fields, saw 5\\nSkipping line 45641: expected 4 fields, saw 5\\nSkipping line 46177: expected 4 fields, saw 5\\nSkipping line 47418: expected 4 fields, saw 5\\n'\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.0524902702704794"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file_path_en = 'x-final/en/train.tsv'\n",
    "file_path_zh = 'x-final/zh/translated_train.tsv'\n",
    "df_en = pd.read_csv(file_path_en, delimiter='\\t', error_bad_lines=False)\n",
    "df_zh = pd.read_csv(file_path_zh, delimiter='\\t', error_bad_lines=False)\n",
    "\n",
    "merged_df = pd.merge(df_en, df_zh, on=\"id\", suffixes=('_en', '_zh'))\n",
    "\n",
    "english_texts1 = merged_df['sentence1_en'].astype(str)\n",
    "chinese_texts1 = merged_df['sentence1_zh'].astype(str)\n",
    "english_texts2 = merged_df['sentence2_en'].astype(str)\n",
    "chinese_texts2 = merged_df['sentence2_zh'].astype(str)\n",
    "\n",
    "syntactic_similarities1 = [syntactic_similarity(pos_tag_sentence(en), pos_tag_sentence(fr)) for en, fr in zip(english_texts1, chinese_texts1)]\n",
    "syntactic_similarities2 = [syntactic_similarity(pos_tag_sentence(en), pos_tag_sentence(fr)) for en, fr in zip(english_texts2, chinese_texts2)]\n",
    "\n",
    "# Calculate average syntactic similarity\n",
    "average_syntactic_similarity1 = sum(syntactic_similarities1) / len(syntactic_similarities1) if syntactic_similarities1 else 0\n",
    "average_syntactic_similarity2 = sum(syntactic_similarities2) / len(syntactic_similarities2) if syntactic_similarities2 else 0\n",
    "\n",
    "average_syntactic_similarity = (average_syntactic_similarity1 + average_syntactic_similarity2) / 2\n",
    "\n",
    "average_syntactic_similarity"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "254a3dde-2174-4221-ac90-009948b067ba",
   "metadata": {},
   "source": [
    "### FR-ES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c41a8f9b-8aba-4776-8d0e-402f8887327a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5617415621271628"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file_path_en = 'x-final/fr/translated_train.tsv'\n",
    "file_path_zh = 'x-final/es/translated_train.tsv'\n",
    "df_en = pd.read_csv(file_path_en, delimiter='\\t', error_bad_lines=False)\n",
    "df_zh = pd.read_csv(file_path_zh, delimiter='\\t', error_bad_lines=False)\n",
    "\n",
    "merged_df = pd.merge(df_en, df_zh, on=\"id\", suffixes=('_en', '_zh'))\n",
    "\n",
    "english_texts1 = merged_df['sentence1_en'].astype(str)\n",
    "chinese_texts1 = merged_df['sentence1_zh'].astype(str)\n",
    "english_texts2 = merged_df['sentence2_en'].astype(str)\n",
    "chinese_texts2 = merged_df['sentence2_zh'].astype(str)\n",
    "\n",
    "syntactic_similarities1 = [syntactic_similarity(pos_tag_sentence(en), pos_tag_sentence(fr)) for en, fr in zip(english_texts1, chinese_texts1)]\n",
    "syntactic_similarities2 = [syntactic_similarity(pos_tag_sentence(en), pos_tag_sentence(fr)) for en, fr in zip(english_texts2, chinese_texts2)]\n",
    "\n",
    "# Calculate average syntactic similarity\n",
    "average_syntactic_similarity1 = sum(syntactic_similarities1) / len(syntactic_similarities1) if syntactic_similarities1 else 0\n",
    "average_syntactic_similarity2 = sum(syntactic_similarities2) / len(syntactic_similarities2) if syntactic_similarities2 else 0\n",
    "\n",
    "average_syntactic_similarity = (average_syntactic_similarity1 + average_syntactic_similarity2) / 2\n",
    "\n",
    "average_syntactic_similarity"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d9e3ec5-9e77-4777-81d7-a20d8810fc43",
   "metadata": {},
   "source": [
    "### FR-DE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "351d41e2-fb74-4a11-8885-4ceb6eb61b8f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4436560749674848"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file_path_ko = 'x-final/fr/translated_train.tsv'\n",
    "file_path_zh = 'x-final/de/translated_train.tsv'\n",
    "df_ko = pd.read_csv(file_path_ko, delimiter='\\t', error_bad_lines=False)\n",
    "df_zh = pd.read_csv(file_path_zh, delimiter='\\t', error_bad_lines=False)\n",
    "\n",
    "merged_df = pd.merge(df_ko, df_zh, on=\"id\", suffixes=('_en', '_zh'))\n",
    "\n",
    "english_texts1 = merged_df['sentence1_en'].astype(str)\n",
    "chinese_texts1 = merged_df['sentence1_zh'].astype(str)\n",
    "english_texts2 = merged_df['sentence2_en'].astype(str)\n",
    "chinese_texts2 = merged_df['sentence2_zh'].astype(str)\n",
    "\n",
    "syntactic_similarities1 = [syntactic_similarity(pos_tag_sentence(en), pos_tag_sentence(fr)) for en, fr in zip(english_texts1, chinese_texts1)]\n",
    "syntactic_similarities2 = [syntactic_similarity(pos_tag_sentence(en), pos_tag_sentence(fr)) for en, fr in zip(english_texts2, chinese_texts2)]\n",
    "\n",
    "# Calculate average syntactic similarity\n",
    "average_syntactic_similarity1 = sum(syntactic_similarities1) / len(syntactic_similarities1) if syntactic_similarities1 else 0\n",
    "average_syntactic_similarity2 = sum(syntactic_similarities2) / len(syntactic_similarities2) if syntactic_similarities2 else 0\n",
    "\n",
    "average_syntactic_similarity = (average_syntactic_similarity1 + average_syntactic_similarity2) / 2\n",
    "\n",
    "average_syntactic_similarity"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9fae3c5-c2dd-4d6e-88b4-36ea365e7fb5",
   "metadata": {},
   "source": [
    "### FR-KO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c45f8f28-3db7-40b6-ab97-be5fbe55b8af",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "b'Skipping line 1250: expected 4 fields, saw 5\\nSkipping line 1680: expected 4 fields, saw 5\\nSkipping line 2165: expected 4 fields, saw 5\\nSkipping line 7642: expected 4 fields, saw 5\\nSkipping line 15126: expected 4 fields, saw 5\\n'\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.39805873924419033"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file_path_ko = 'x-final/fr/translated_train.tsv'\n",
    "file_path_zh = 'x-final/ko/translated_train.tsv'\n",
    "df_ko = pd.read_csv(file_path_ko, delimiter='\\t', error_bad_lines=False)\n",
    "df_zh = pd.read_csv(file_path_zh, delimiter='\\t', error_bad_lines=False)\n",
    "\n",
    "merged_df = pd.merge(df_ko, df_zh, on=\"id\", suffixes=('_en', '_zh'))\n",
    "\n",
    "english_texts1 = merged_df['sentence1_en'].astype(str)\n",
    "chinese_texts1 = merged_df['sentence1_zh'].astype(str)\n",
    "english_texts2 = merged_df['sentence2_en'].astype(str)\n",
    "chinese_texts2 = merged_df['sentence2_zh'].astype(str)\n",
    "\n",
    "syntactic_similarities1 = [syntactic_similarity(pos_tag_sentence(en), pos_tag_sentence(fr)) for en, fr in zip(english_texts1, chinese_texts1)]\n",
    "syntactic_similarities2 = [syntactic_similarity(pos_tag_sentence(en), pos_tag_sentence(fr)) for en, fr in zip(english_texts2, chinese_texts2)]\n",
    "\n",
    "# Calculate average syntactic similarity\n",
    "average_syntactic_similarity1 = sum(syntactic_similarities1) / len(syntactic_similarities1) if syntactic_similarities1 else 0\n",
    "average_syntactic_similarity2 = sum(syntactic_similarities2) / len(syntactic_similarities2) if syntactic_similarities2 else 0\n",
    "\n",
    "average_syntactic_similarity = (average_syntactic_similarity1 + average_syntactic_similarity2) / 2\n",
    "\n",
    "average_syntactic_similarity"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0add3459-c9b1-44c4-8357-694c0901ebc1",
   "metadata": {},
   "source": [
    "### FR-JA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0a82f8a6-8da7-4313-81ae-db3763b0db34",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.053824086953983726"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file_path_ko = 'x-final/fr/translated_train.tsv'\n",
    "file_path_zh = 'x-final/ja/translated_train.tsv'\n",
    "df_ko = pd.read_csv(file_path_ko, delimiter='\\t', error_bad_lines=False)\n",
    "df_zh = pd.read_csv(file_path_zh, delimiter='\\t', error_bad_lines=False)\n",
    "\n",
    "merged_df = pd.merge(df_ko, df_zh, on=\"id\", suffixes=('_en', '_zh'))\n",
    "\n",
    "english_texts1 = merged_df['sentence1_en'].astype(str)\n",
    "chinese_texts1 = merged_df['sentence1_zh'].astype(str)\n",
    "english_texts2 = merged_df['sentence2_en'].astype(str)\n",
    "chinese_texts2 = merged_df['sentence2_zh'].astype(str)\n",
    "\n",
    "syntactic_similarities1 = [syntactic_similarity(pos_tag_sentence(en), pos_tag_sentence(fr)) for en, fr in zip(english_texts1, chinese_texts1)]\n",
    "syntactic_similarities2 = [syntactic_similarity(pos_tag_sentence(en), pos_tag_sentence(fr)) for en, fr in zip(english_texts2, chinese_texts2)]\n",
    "\n",
    "# Calculate average syntactic similarity\n",
    "average_syntactic_similarity1 = sum(syntactic_similarities1) / len(syntactic_similarities1) if syntactic_similarities1 else 0\n",
    "average_syntactic_similarity2 = sum(syntactic_similarities2) / len(syntactic_similarities2) if syntactic_similarities2 else 0\n",
    "\n",
    "average_syntactic_similarity = (average_syntactic_similarity1 + average_syntactic_similarity2) / 2\n",
    "\n",
    "average_syntactic_similarity"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35c2d108-4b96-4824-bdeb-e6a27f1a25a8",
   "metadata": {},
   "source": [
    "### FR-ZH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "25785b7b-72a5-4e0d-947d-d36bd975efdc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.07380704877061381"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file_path_ko = 'x-final/fr/translated_train.tsv'\n",
    "file_path_zh = 'x-final/zh/translated_train.tsv'\n",
    "df_ko = pd.read_csv(file_path_ko, delimiter='\\t', error_bad_lines=False)\n",
    "df_zh = pd.read_csv(file_path_zh, delimiter='\\t', error_bad_lines=False)\n",
    "\n",
    "merged_df = pd.merge(df_ko, df_zh, on=\"id\", suffixes=('_en', '_zh'))\n",
    "\n",
    "english_texts1 = merged_df['sentence1_en'].astype(str)\n",
    "chinese_texts1 = merged_df['sentence1_zh'].astype(str)\n",
    "english_texts2 = merged_df['sentence2_en'].astype(str)\n",
    "chinese_texts2 = merged_df['sentence2_zh'].astype(str)\n",
    "\n",
    "syntactic_similarities1 = [syntactic_similarity(pos_tag_sentence(en), pos_tag_sentence(fr)) for en, fr in zip(english_texts1, chinese_texts1)]\n",
    "syntactic_similarities2 = [syntactic_similarity(pos_tag_sentence(en), pos_tag_sentence(fr)) for en, fr in zip(english_texts2, chinese_texts2)]\n",
    "\n",
    "# Calculate average syntactic similarity\n",
    "average_syntactic_similarity1 = sum(syntactic_similarities1) / len(syntactic_similarities1) if syntactic_similarities1 else 0\n",
    "average_syntactic_similarity2 = sum(syntactic_similarities2) / len(syntactic_similarities2) if syntactic_similarities2 else 0\n",
    "\n",
    "average_syntactic_similarity = (average_syntactic_similarity1 + average_syntactic_similarity2) / 2\n",
    "\n",
    "average_syntactic_similarity"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efcc53e9-358b-4df5-87e0-dabe59078bca",
   "metadata": {},
   "source": [
    "### ES-DE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a7662bed-34f6-41fe-9cc5-13028084f339",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4760827192765159"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file_path_ko = 'x-final/es/translated_train.tsv'\n",
    "file_path_zh = 'x-final/de/translated_train.tsv'\n",
    "df_ko = pd.read_csv(file_path_ko, delimiter='\\t', error_bad_lines=False)\n",
    "df_zh = pd.read_csv(file_path_zh, delimiter='\\t', error_bad_lines=False)\n",
    "\n",
    "merged_df = pd.merge(df_ko, df_zh, on=\"id\", suffixes=('_en', '_zh'))\n",
    "\n",
    "english_texts1 = merged_df['sentence1_en'].astype(str)\n",
    "chinese_texts1 = merged_df['sentence1_zh'].astype(str)\n",
    "english_texts2 = merged_df['sentence2_en'].astype(str)\n",
    "chinese_texts2 = merged_df['sentence2_zh'].astype(str)\n",
    "\n",
    "syntactic_similarities1 = [syntactic_similarity(pos_tag_sentence(en), pos_tag_sentence(fr)) for en, fr in zip(english_texts1, chinese_texts1)]\n",
    "syntactic_similarities2 = [syntactic_similarity(pos_tag_sentence(en), pos_tag_sentence(fr)) for en, fr in zip(english_texts2, chinese_texts2)]\n",
    "\n",
    "# Calculate average syntactic similarity\n",
    "average_syntactic_similarity1 = sum(syntactic_similarities1) / len(syntactic_similarities1) if syntactic_similarities1 else 0\n",
    "average_syntactic_similarity2 = sum(syntactic_similarities2) / len(syntactic_similarities2) if syntactic_similarities2 else 0\n",
    "\n",
    "average_syntactic_similarity = (average_syntactic_similarity1 + average_syntactic_similarity2) / 2\n",
    "\n",
    "average_syntactic_similarity"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c61f7419-ada4-4d3f-bad0-4b1ef05d7c60",
   "metadata": {},
   "source": [
    "### ES-KO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a7bdc70e-ef40-4e46-b667-24afdaf0115b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "b'Skipping line 1250: expected 4 fields, saw 5\\nSkipping line 1680: expected 4 fields, saw 5\\nSkipping line 2165: expected 4 fields, saw 5\\nSkipping line 7642: expected 4 fields, saw 5\\nSkipping line 15126: expected 4 fields, saw 5\\n'\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.44104245255853536"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file_path_ko = 'x-final/es/translated_train.tsv'\n",
    "file_path_zh = 'x-final/ko/translated_train.tsv'\n",
    "df_ko = pd.read_csv(file_path_ko, delimiter='\\t', error_bad_lines=False)\n",
    "df_zh = pd.read_csv(file_path_zh, delimiter='\\t', error_bad_lines=False)\n",
    "\n",
    "merged_df = pd.merge(df_ko, df_zh, on=\"id\", suffixes=('_en', '_zh'))\n",
    "\n",
    "english_texts1 = merged_df['sentence1_en'].astype(str)\n",
    "chinese_texts1 = merged_df['sentence1_zh'].astype(str)\n",
    "english_texts2 = merged_df['sentence2_en'].astype(str)\n",
    "chinese_texts2 = merged_df['sentence2_zh'].astype(str)\n",
    "\n",
    "syntactic_similarities1 = [syntactic_similarity(pos_tag_sentence(en), pos_tag_sentence(fr)) for en, fr in zip(english_texts1, chinese_texts1)]\n",
    "syntactic_similarities2 = [syntactic_similarity(pos_tag_sentence(en), pos_tag_sentence(fr)) for en, fr in zip(english_texts2, chinese_texts2)]\n",
    "\n",
    "# Calculate average syntactic similarity\n",
    "average_syntactic_similarity1 = sum(syntactic_similarities1) / len(syntactic_similarities1) if syntactic_similarities1 else 0\n",
    "average_syntactic_similarity2 = sum(syntactic_similarities2) / len(syntactic_similarities2) if syntactic_similarities2 else 0\n",
    "\n",
    "average_syntactic_similarity = (average_syntactic_similarity1 + average_syntactic_similarity2) / 2\n",
    "\n",
    "average_syntactic_similarity"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4ffe8b1-d77f-4061-a322-9a022e8637d9",
   "metadata": {},
   "source": [
    "### ES-JA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "13fd2977-7538-4a35-88f0-31610a1a6ae7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.06167180805851999"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file_path_ko = 'x-final/es/translated_train.tsv'\n",
    "file_path_zh = 'x-final/ja/translated_train.tsv'\n",
    "df_ko = pd.read_csv(file_path_ko, delimiter='\\t', error_bad_lines=False)\n",
    "df_zh = pd.read_csv(file_path_zh, delimiter='\\t', error_bad_lines=False)\n",
    "\n",
    "merged_df = pd.merge(df_ko, df_zh, on=\"id\", suffixes=('_en', '_zh'))\n",
    "\n",
    "english_texts1 = merged_df['sentence1_en'].astype(str)\n",
    "chinese_texts1 = merged_df['sentence1_zh'].astype(str)\n",
    "english_texts2 = merged_df['sentence2_en'].astype(str)\n",
    "chinese_texts2 = merged_df['sentence2_zh'].astype(str)\n",
    "\n",
    "syntactic_similarities1 = [syntactic_similarity(pos_tag_sentence(en), pos_tag_sentence(fr)) for en, fr in zip(english_texts1, chinese_texts1)]\n",
    "syntactic_similarities2 = [syntactic_similarity(pos_tag_sentence(en), pos_tag_sentence(fr)) for en, fr in zip(english_texts2, chinese_texts2)]\n",
    "\n",
    "# Calculate average syntactic similarity\n",
    "average_syntactic_similarity1 = sum(syntactic_similarities1) / len(syntactic_similarities1) if syntactic_similarities1 else 0\n",
    "average_syntactic_similarity2 = sum(syntactic_similarities2) / len(syntactic_similarities2) if syntactic_similarities2 else 0\n",
    "\n",
    "average_syntactic_similarity = (average_syntactic_similarity1 + average_syntactic_similarity2) / 2\n",
    "\n",
    "average_syntactic_similarity"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f79f555-28c9-4687-afee-2ee0bf02858b",
   "metadata": {},
   "source": [
    "### ES-ZH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "8208ad09-af22-4a6d-9f5a-c79af8e33a49",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0843166670624586"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file_path_ko = 'x-final/es/translated_train.tsv'\n",
    "file_path_zh = 'x-final/zh/translated_train.tsv'\n",
    "df_ko = pd.read_csv(file_path_ko, delimiter='\\t', error_bad_lines=False)\n",
    "df_zh = pd.read_csv(file_path_zh, delimiter='\\t', error_bad_lines=False)\n",
    "\n",
    "merged_df = pd.merge(df_ko, df_zh, on=\"id\", suffixes=('_en', '_zh'))\n",
    "\n",
    "english_texts1 = merged_df['sentence1_en'].astype(str)\n",
    "chinese_texts1 = merged_df['sentence1_zh'].astype(str)\n",
    "english_texts2 = merged_df['sentence2_en'].astype(str)\n",
    "chinese_texts2 = merged_df['sentence2_zh'].astype(str)\n",
    "\n",
    "syntactic_similarities1 = [syntactic_similarity(pos_tag_sentence(en), pos_tag_sentence(fr)) for en, fr in zip(english_texts1, chinese_texts1)]\n",
    "syntactic_similarities2 = [syntactic_similarity(pos_tag_sentence(en), pos_tag_sentence(fr)) for en, fr in zip(english_texts2, chinese_texts2)]\n",
    "\n",
    "# Calculate average syntactic similarity\n",
    "average_syntactic_similarity1 = sum(syntactic_similarities1) / len(syntactic_similarities1) if syntactic_similarities1 else 0\n",
    "average_syntactic_similarity2 = sum(syntactic_similarities2) / len(syntactic_similarities2) if syntactic_similarities2 else 0\n",
    "\n",
    "average_syntactic_similarity = (average_syntactic_similarity1 + average_syntactic_similarity2) / 2\n",
    "\n",
    "average_syntactic_similarity"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13bc50f7-d374-46fa-ad2e-55d891970dfe",
   "metadata": {},
   "source": [
    "### DE-KO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "332341a3-b4af-4dad-8346-97864507df0b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "b'Skipping line 1250: expected 4 fields, saw 5\\nSkipping line 1680: expected 4 fields, saw 5\\nSkipping line 2165: expected 4 fields, saw 5\\nSkipping line 7642: expected 4 fields, saw 5\\nSkipping line 15126: expected 4 fields, saw 5\\n'\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.520982067215189"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file_path_ko = 'x-final/de/translated_train.tsv'\n",
    "file_path_zh = 'x-final/ko/translated_train.tsv'\n",
    "df_ko = pd.read_csv(file_path_ko, delimiter='\\t', error_bad_lines=False)\n",
    "df_zh = pd.read_csv(file_path_zh, delimiter='\\t', error_bad_lines=False)\n",
    "\n",
    "merged_df = pd.merge(df_ko, df_zh, on=\"id\", suffixes=('_en', '_zh'))\n",
    "\n",
    "english_texts1 = merged_df['sentence1_en'].astype(str)\n",
    "chinese_texts1 = merged_df['sentence1_zh'].astype(str)\n",
    "english_texts2 = merged_df['sentence2_en'].astype(str)\n",
    "chinese_texts2 = merged_df['sentence2_zh'].astype(str)\n",
    "\n",
    "syntactic_similarities1 = [syntactic_similarity(pos_tag_sentence(en), pos_tag_sentence(fr)) for en, fr in zip(english_texts1, chinese_texts1)]\n",
    "syntactic_similarities2 = [syntactic_similarity(pos_tag_sentence(en), pos_tag_sentence(fr)) for en, fr in zip(english_texts2, chinese_texts2)]\n",
    "\n",
    "# Calculate average syntactic similarity\n",
    "average_syntactic_similarity1 = sum(syntactic_similarities1) / len(syntactic_similarities1) if syntactic_similarities1 else 0\n",
    "average_syntactic_similarity2 = sum(syntactic_similarities2) / len(syntactic_similarities2) if syntactic_similarities2 else 0\n",
    "\n",
    "average_syntactic_similarity = (average_syntactic_similarity1 + average_syntactic_similarity2) / 2\n",
    "\n",
    "average_syntactic_similarity"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef5bceb5-0dd9-4d86-aae1-12cbdffe3e92",
   "metadata": {},
   "source": [
    "### DE-JA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "07f3eb5f-7991-4e60-bd51-3877554e286c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.07377742464607281"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file_path_ko = 'x-final/de/translated_train.tsv'\n",
    "file_path_zh = 'x-final/ja/translated_train.tsv'\n",
    "df_ko = pd.read_csv(file_path_ko, delimiter='\\t', error_bad_lines=False)\n",
    "df_zh = pd.read_csv(file_path_zh, delimiter='\\t', error_bad_lines=False)\n",
    "\n",
    "merged_df = pd.merge(df_ko, df_zh, on=\"id\", suffixes=('_en', '_zh'))\n",
    "\n",
    "english_texts1 = merged_df['sentence1_en'].astype(str)\n",
    "chinese_texts1 = merged_df['sentence1_zh'].astype(str)\n",
    "english_texts2 = merged_df['sentence2_en'].astype(str)\n",
    "chinese_texts2 = merged_df['sentence2_zh'].astype(str)\n",
    "\n",
    "syntactic_similarities1 = [syntactic_similarity(pos_tag_sentence(en), pos_tag_sentence(fr)) for en, fr in zip(english_texts1, chinese_texts1)]\n",
    "syntactic_similarities2 = [syntactic_similarity(pos_tag_sentence(en), pos_tag_sentence(fr)) for en, fr in zip(english_texts2, chinese_texts2)]\n",
    "\n",
    "# Calculate average syntactic similarity\n",
    "average_syntactic_similarity1 = sum(syntactic_similarities1) / len(syntactic_similarities1) if syntactic_similarities1 else 0\n",
    "average_syntactic_similarity2 = sum(syntactic_similarities2) / len(syntactic_similarities2) if syntactic_similarities2 else 0\n",
    "\n",
    "average_syntactic_similarity = (average_syntactic_similarity1 + average_syntactic_similarity2) / 2\n",
    "\n",
    "average_syntactic_similarity"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51e63e4e-99ae-4d6d-9e7f-b52d246768cc",
   "metadata": {},
   "source": [
    "### DE-ZH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "811ddeac-0b2d-441b-9b27-3dd66c93da00",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.09969023494216837"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file_path_ko = 'x-final/de/translated_train.tsv'\n",
    "file_path_zh = 'x-final/zh/translated_train.tsv'\n",
    "df_ko = pd.read_csv(file_path_ko, delimiter='\\t', error_bad_lines=False)\n",
    "df_zh = pd.read_csv(file_path_zh, delimiter='\\t', error_bad_lines=False)\n",
    "\n",
    "merged_df = pd.merge(df_ko, df_zh, on=\"id\", suffixes=('_en', '_zh'))\n",
    "\n",
    "english_texts1 = merged_df['sentence1_en'].astype(str)\n",
    "chinese_texts1 = merged_df['sentence1_zh'].astype(str)\n",
    "english_texts2 = merged_df['sentence2_en'].astype(str)\n",
    "chinese_texts2 = merged_df['sentence2_zh'].astype(str)\n",
    "\n",
    "syntactic_similarities1 = [syntactic_similarity(pos_tag_sentence(en), pos_tag_sentence(fr)) for en, fr in zip(english_texts1, chinese_texts1)]\n",
    "syntactic_similarities2 = [syntactic_similarity(pos_tag_sentence(en), pos_tag_sentence(fr)) for en, fr in zip(english_texts2, chinese_texts2)]\n",
    "\n",
    "# Calculate average syntactic similarity\n",
    "average_syntactic_similarity1 = sum(syntactic_similarities1) / len(syntactic_similarities1) if syntactic_similarities1 else 0\n",
    "average_syntactic_similarity2 = sum(syntactic_similarities2) / len(syntactic_similarities2) if syntactic_similarities2 else 0\n",
    "\n",
    "average_syntactic_similarity = (average_syntactic_similarity1 + average_syntactic_similarity2) / 2\n",
    "\n",
    "average_syntactic_similarity"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e99af4cc-0c67-45ea-b525-8ee4684b7030",
   "metadata": {},
   "source": [
    "### KO-JA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "75bb43b9-0583-416d-b223-c9edfefe2856",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "b'Skipping line 1250: expected 4 fields, saw 5\\nSkipping line 1680: expected 4 fields, saw 5\\nSkipping line 2165: expected 4 fields, saw 5\\nSkipping line 7642: expected 4 fields, saw 5\\nSkipping line 15126: expected 4 fields, saw 5\\n'\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.11707716900507242"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file_path_ko = 'x-final/ko/translated_train.tsv'\n",
    "file_path_zh = 'x-final/ja/translated_train.tsv'\n",
    "df_ko = pd.read_csv(file_path_ko, delimiter='\\t', error_bad_lines=False)\n",
    "df_zh = pd.read_csv(file_path_zh, delimiter='\\t', error_bad_lines=False)\n",
    "\n",
    "merged_df = pd.merge(df_ko, df_zh, on=\"id\", suffixes=('_en', '_zh'))\n",
    "\n",
    "english_texts1 = merged_df['sentence1_en'].astype(str)\n",
    "chinese_texts1 = merged_df['sentence1_zh'].astype(str)\n",
    "english_texts2 = merged_df['sentence2_en'].astype(str)\n",
    "chinese_texts2 = merged_df['sentence2_zh'].astype(str)\n",
    "\n",
    "syntactic_similarities1 = [syntactic_similarity(pos_tag_sentence(en), pos_tag_sentence(fr)) for en, fr in zip(english_texts1, chinese_texts1)]\n",
    "syntactic_similarities2 = [syntactic_similarity(pos_tag_sentence(en), pos_tag_sentence(fr)) for en, fr in zip(english_texts2, chinese_texts2)]\n",
    "\n",
    "# Calculate average syntactic similarity\n",
    "average_syntactic_similarity1 = sum(syntactic_similarities1) / len(syntactic_similarities1) if syntactic_similarities1 else 0\n",
    "average_syntactic_similarity2 = sum(syntactic_similarities2) / len(syntactic_similarities2) if syntactic_similarities2 else 0\n",
    "\n",
    "average_syntactic_similarity = (average_syntactic_similarity1 + average_syntactic_similarity2) / 2\n",
    "\n",
    "average_syntactic_similarity"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73a98b0c-d04a-4435-9a64-ad9408c91bed",
   "metadata": {},
   "source": [
    "### KO-ZH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "9606d0b1-dac0-428a-952c-0a5d193add8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "b'Skipping line 1250: expected 4 fields, saw 5\\nSkipping line 1680: expected 4 fields, saw 5\\nSkipping line 2165: expected 4 fields, saw 5\\nSkipping line 7642: expected 4 fields, saw 5\\nSkipping line 15126: expected 4 fields, saw 5\\n'\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.15546188491522395"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file_path_ko = 'x-final/ko/translated_train.tsv'\n",
    "file_path_zh = 'x-final/zh/translated_train.tsv'\n",
    "df_ko = pd.read_csv(file_path_ko, delimiter='\\t', error_bad_lines=False)\n",
    "df_zh = pd.read_csv(file_path_zh, delimiter='\\t', error_bad_lines=False)\n",
    "\n",
    "merged_df = pd.merge(df_ko, df_zh, on=\"id\", suffixes=('_en', '_zh'))\n",
    "\n",
    "english_texts1 = merged_df['sentence1_en'].astype(str)\n",
    "chinese_texts1 = merged_df['sentence1_zh'].astype(str)\n",
    "english_texts2 = merged_df['sentence2_en'].astype(str)\n",
    "chinese_texts2 = merged_df['sentence2_zh'].astype(str)\n",
    "\n",
    "syntactic_similarities1 = [syntactic_similarity(pos_tag_sentence(en), pos_tag_sentence(fr)) for en, fr in zip(english_texts1, chinese_texts1)]\n",
    "syntactic_similarities2 = [syntactic_similarity(pos_tag_sentence(en), pos_tag_sentence(fr)) for en, fr in zip(english_texts2, chinese_texts2)]\n",
    "\n",
    "# Calculate average syntactic similarity\n",
    "average_syntactic_similarity1 = sum(syntactic_similarities1) / len(syntactic_similarities1) if syntactic_similarities1 else 0\n",
    "average_syntactic_similarity2 = sum(syntactic_similarities2) / len(syntactic_similarities2) if syntactic_similarities2 else 0\n",
    "\n",
    "average_syntactic_similarity = (average_syntactic_similarity1 + average_syntactic_similarity2) / 2\n",
    "\n",
    "average_syntactic_similarity"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1aea6ea9-4bd1-47ec-b050-ed2cc026e510",
   "metadata": {},
   "source": [
    "### JA-ZH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "f9c12ba5-5269-4551-b594-cef6486860ae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.15707728588490047"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file_path_ko = 'x-final/ja/translated_train.tsv'\n",
    "file_path_zh = 'x-final/zh/translated_train.tsv'\n",
    "df_ko = pd.read_csv(file_path_ko, delimiter='\\t', error_bad_lines=False)\n",
    "df_zh = pd.read_csv(file_path_zh, delimiter='\\t', error_bad_lines=False)\n",
    "\n",
    "merged_df = pd.merge(df_ko, df_zh, on=\"id\", suffixes=('_en', '_zh'))\n",
    "\n",
    "english_texts1 = merged_df['sentence1_en'].astype(str)\n",
    "chinese_texts1 = merged_df['sentence1_zh'].astype(str)\n",
    "english_texts2 = merged_df['sentence2_en'].astype(str)\n",
    "chinese_texts2 = merged_df['sentence2_zh'].astype(str)\n",
    "\n",
    "syntactic_similarities1 = [syntactic_similarity(pos_tag_sentence(en), pos_tag_sentence(fr)) for en, fr in zip(english_texts1, chinese_texts1)]\n",
    "syntactic_similarities2 = [syntactic_similarity(pos_tag_sentence(en), pos_tag_sentence(fr)) for en, fr in zip(english_texts2, chinese_texts2)]\n",
    "\n",
    "# Calculate average syntactic similarity\n",
    "average_syntactic_similarity1 = sum(syntactic_similarities1) / len(syntactic_similarities1) if syntactic_similarities1 else 0\n",
    "average_syntactic_similarity2 = sum(syntactic_similarities2) / len(syntactic_similarities2) if syntactic_similarities2 else 0\n",
    "\n",
    "average_syntactic_similarity = (average_syntactic_similarity1 + average_syntactic_similarity2) / 2\n",
    "\n",
    "average_syntactic_similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd0694bc-0bab-47d3-aac7-ff10616e9c63",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "766545e6-4d5d-4b5f-9e34-9294336300e7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "256a6e4f-4dc5-41d6-874e-93cee1cd1e57",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
