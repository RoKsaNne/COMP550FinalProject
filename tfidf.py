# -*- coding: utf-8 -*-
"""tfidf.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/17YDHt_MCh0urWt_03ZwE8C_Z3tr3VGkg
"""

!pip install datasets googletrans==4.0.0-rc1 scikit-learn
import pandas as pd
from sklearn.model_selection import train_test_split
from datasets import load_dataset
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.svm import SVC
from sklearn.metrics import classification_report
from googletrans import Translator
import torch
from transformers import AutoTokenizer, AutoModel
from sklearn.svm import SVC
from sklearn.ensemble import RandomForestClassifier
from sklearn.linear_model import LogisticRegression
from sklearn.neighbors import KNeighborsClassifier
from sklearn.model_selection import GridSearchCV
from google.colab import drive

# Commented out IPython magic to ensure Python compatibility.
from google.colab import drive

def load_dataset(train_lang, test_lang):
    drive.mount('/content/drive')
#     %cd /content/drive/My Drive/colab/new
    path = 'train.tsv'
    path2 = f"translated_{test_lang}.tsv"
    # training in lang1
    data1 = pd.read_csv(path, sep='\t', nrows=10000, error_bad_lines=False)
    df1_sentences = data1['sentence1'] + " " + data1['sentence2']
    df1_labels = data1['label'].tolist()
    # tesing in lang2 on parallel corpora -> comment out below lines if for parallel testing
    data2 = pd.read_csv(path2, sep='\t', nrows=10000,error_bad_lines=False)
    df2_sentences = data2['sentence1'] + " " + data2['sentence2']
    df2_labels = data2['label'].tolist()

    # on brand new dataset in lang2/en
    # df2_sentences = pd.read_csv(path, sep='\t', skiprows=range(1, 10001), nrows=10000, error_bad_lines=False)
    # df2_sentences = pd.read_csv(path2, sep='\t', skiprows=range(1, 10001), nrows=10000, error_bad_lines=False)
    # df2_labels = df2_sentences['label'].tolist()
    # df2_sentences = df2_sentences['sentence1'] + " " + df2_sentences['sentence2']

    # remove nan
    df1_sentences = [text for text, label in zip(df1_sentences, df1_labels) if not pd.isna(label)]
    df1_labels = [label for label in df1_labels if not pd.isna(label)]
    df2_sentences = [text for text, label in zip(df2_sentences, df2_labels) if not pd.isna(label)]
    df2_labels = [label for label in df2_labels if not pd.isna(label)]
    # convert to string
    df1_sentences = [str(text) for text in df1_sentences]
    df2_sentences = [str(text) for text in df2_sentences]
    return df1_sentences, df1_labels, df2_sentences, df2_labels


def load_new_dataset(lang):
    from google.colab import drive
    drive.mount('/content/drive')
#     %cd /content/drive/My Drive/colab/new
    if lang == 'en':
        path = 'train.tsv'
    else:
        path = f"translated_{lang}.tsv"
    # on brand new corpus
    data = pd.read_csv(path, sep='\t', skiprows=range(1, 10001),nrows=10000,error_bad_lines=False)
    df_sentences = data['sentence1'] + " " + data['sentence2']
    df_labels = data['label'].tolist()
    df_sentences = [str(text) for text in df_sentences]
    # remove Nan
    df_sentences_clean = [text for text, label in zip(df_sentences, df_labels) if not pd.isna(label)]
    df_labels_clean = [label for label in df_labels if not pd.isna(label)]

    return df2_sentences_clean, df2_labels_clean


def vectorize_sentences(train_sentences, test_sentences):
    vectorizer = TfidfVectorizer()
    X_train = vectorizer.fit_transform(train_sentences)
    X_test = vectorizer.transform(test_sentences)
    return X_train, X_test

def train_and_evaluate_classifier(clf,X_train, y_train, X_test, y_test):
    clf.fit(X_train, y_train)
    predictions = clf.predict(X_test)
    r=classification_report(y_test, predictions)
    print(r)
    return r

test_lang = "zh"
train_lang = "en"
train_sentences, train_labels, test_sentences, test_labels = load_dataset(train_lang, test_lang)
test_sentences_new, test_labels_new = load_new_dataset(test_lang)



svm_classifier = SVC()
knn_classifier = KNeighborsClassifier(n_neighbors=2)
logistic_classifier = LogisticRegression()
# tfidf
X_train, X_test = vectorize_sentences(train_sentences, test_sentences)
X_train,X_test_new=vectorize_sentences(train_sentences, test_sentences_new)
svm_report_tf=train_and_evaluate_classifier(svm_classifier,X_train, train_labels, X_test, test_labels)
knn_report_tf=train_and_evaluate_classifier(knn_classifier,X_train, train_labels, X_test, test_labels)
lr_report_tf=train_and_evaluate_classifier(logistic_classifier,X_train, train_labels, X_test, test_labels)

print("with brand new testing dataset")
svm_classifier2 = SVC()
knn_classifier2 = KNeighborsClassifier(n_neighbors=2)
logistic_classifier2 = LogisticRegression()

svm_report_tf=train_and_evaluate_classifier(svm_classifier2,X_train, train_labels, X_test_new, test_labels_new)
knn_report_tf=train_and_evaluate_classifier(knn_classifier2,X_train, train_labels, X_test_new, test_labels_new)
lr_report_tf=train_and_evaluate_classifier(logistic_classifier2,X_train, train_labels, X_test_new, test_labels_new)